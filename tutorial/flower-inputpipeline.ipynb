{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems\n",
    "\n",
    "* 행이 걸리는 경우가 있음\n",
    "    * tfrecords 를 안만들어도 될 때 writer_io 로 열고 그냥 넘어갔음\n",
    "    * 이렇게 되면 데이터가 다 지워짐\n",
    "    * 이상태에서 실행하면 행이 걸림!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, glob, shutil\n",
    "import urllib\n",
    "import tarfile\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_file(url, dest=None):\n",
    "    if not dest:\n",
    "        dest = 'data/' + url.split('/')[-1]\n",
    "    urllib.urlretrieve(url, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download TF Flower dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABELS = [\"daisy\", \"dandelion\", \"roses\", \"sunflowers\", \"tulips\"]\n",
    "url = \"http://download.tensorflow.org/example_images/flower_photos.tgz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data/flower_photos\"):\n",
    "    print(\"Download flower dataset..\")\n",
    "    download_file(url)\n",
    "    print(\"Extracting dataset..\")\n",
    "    tarfile.open(\"data/flower_photos.tgz\", \"r:gz\").extractall(path=\"data/\")\n",
    "#     os.remove(\"data/flower_photos.tgz\") # 굳이..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "remake = False\n",
    "parent_dir = \"data/flower_photos\"\n",
    "train_dir = os.path.join(parent_dir, \"train\")\n",
    "test_dir = os.path.join(parent_dir, \"test\")\n",
    "\n",
    "if not os.path.exists(train_dir) or not os.path.exists(test_dir) or remake:\n",
    "    # make dirs\n",
    "    for label in LABELS:\n",
    "        # tf.gfile.MakeDirs make dir recursively & ignore exist dir\n",
    "        tf.gfile.MakeDirs(os.path.join(train_dir, label))\n",
    "        tf.gfile.MakeDirs(os.path.join(test_dir, label))\n",
    "\n",
    "    # copy files\n",
    "    for i, label in enumerate(LABELS):\n",
    "        dir_name = os.path.join(parent_dir, label)\n",
    "        paths = glob.glob(dir_name + \"/*.jpg\")\n",
    "        num_examples = len(paths)\n",
    "        for j, path in enumerate(paths):\n",
    "            fn = os.path.basename(path)\n",
    "            is_train = j < (num_examples * train_ratio)\n",
    "\n",
    "            if is_train:\n",
    "                to_path = os.path.join(train_dir, label, fn)\n",
    "            else:\n",
    "                to_path = os.path.join(test_dir, label, fn)\n",
    "            \n",
    "            tf.gfile.Copy(path, to_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    364 test\r\n",
      "   3306 train\r\n"
     ]
    }
   ],
   "source": [
    "!find ./data/flower_photos/test ./data/flower_photos/train -type f | cut -d/ -f4 | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to `TFRecords` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _bytes_features(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "\n",
    "def _int64_features(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dir_to_tfrecords(dir_name, tfrecords_path):\n",
    "    '''convert image-containing dir to tfrecords without exist check.\n",
    "    return: # of image files\n",
    "    '''\n",
    "    num_files = 0\n",
    "    with tf.python_io.TFRecordWriter(tfrecords_path) as writer:\n",
    "        for i, label in enumerate(LABELS):\n",
    "            cur_dir = os.path.join(dir_name, label)\n",
    "            paths = glob.glob(cur_dir + \"/*.jpg\")\n",
    "            num_examples = len(paths)\n",
    "            for j, path in enumerate(paths):\n",
    "                im = scipy.misc.imread(path)\n",
    "                im = scipy.misc.imresize(im, [64, 64])\n",
    "\n",
    "                im_raw = im.tostring()\n",
    "                features = {\n",
    "                    \"shape\": _int64_features(im.shape),\n",
    "                    \"image\": _bytes_features([im_raw]),\n",
    "                    \"label\": _int64_features([i])\n",
    "                }\n",
    "\n",
    "                example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "\n",
    "                is_train = j < (num_examples * train_ratio)\n",
    "\n",
    "                num_files += 1\n",
    "                writer.write(example.SerializeToString())\n",
    "    \n",
    "    return num_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert dataset to TFRecord format..\n",
      "3306 364\n"
     ]
    }
   ],
   "source": [
    "print(\"Convert dataset to TFRecord format..\")\n",
    "\n",
    "tfrecords_train_fn = \"data/flower_photos_train.tfrecords\"\n",
    "tfrecords_test_fn = \"data/flower_photos_test.tfrecords\"\n",
    "\n",
    "num_train = 0\n",
    "num_test = 0\n",
    "\n",
    "remake_tfrecords = False\n",
    "\n",
    "if not (tf.gfile.Exists(tfrecords_train_fn) and tf.gfile.Exists(tfrecords_test_fn) and remake_tfrecords == False):\n",
    "    num_train = dir_to_tfrecords('data/flower_photos/train/', tfrecords_train_fn)\n",
    "    num_test = dir_to_tfrecords('data/flower_photos/test/', tfrecords_test_fn)\n",
    "else:\n",
    "    num_train = 3306\n",
    "    num_test = 364\n",
    "    \n",
    "# how to get num_examples from tfrecords file?\n",
    "print num_train, num_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(tfrecords_fn, batch_size, shuffle=False):\n",
    "    with tf.variable_scope(\"get_batch\"):\n",
    "        # make input pipeline\n",
    "        filename_queue = tf.train.string_input_producer([tfrecords_fn])\n",
    "        reader = tf.TFRecordReader()\n",
    "        key, records = reader.read(filename_queue)\n",
    "\n",
    "        features = tf.parse_single_example(\n",
    "            records,\n",
    "            features={\n",
    "                \"shape\": tf.FixedLenFeature([3], tf.int64),\n",
    "                \"image\": tf.FixedLenFeature([], tf.string),\n",
    "                \"label\": tf.FixedLenFeature([], tf.int64)\n",
    "            }\n",
    "        )\n",
    "\n",
    "        image = tf.decode_raw(features[\"image\"], tf.uint8)\n",
    "        shape = tf.cast(features[\"shape\"], tf.int32)\n",
    "        label = tf.cast(features[\"label\"], tf.int32)\n",
    "\n",
    "        image = tf.reshape(image, [64, 64, 3])\n",
    "        resized_image = tf.image.resize_images(images=image, size=[64, 64])\n",
    "        resized_image = tf.cast(resized_image, tf.float32)\n",
    "        resized_image = resized_image / 255.0\n",
    "#         resized_image = resized_image / 127.5 - 1.0 \n",
    "#         resized_image = tf.image.per_image_standardization(resized_image)\n",
    "        # 사실 이 normalization 을 굳이 여기서 해 줄 필요는 없을 것 같기는 함\n",
    "        # 다만 TF docs 에는 fn_queue - reader - decoder - preprocessing 으로 되어 있으니 그 위치가 여기는 맞음\n",
    "\n",
    "        one_hot_label = tf.one_hot(label, depth=5)\n",
    "\n",
    "        # 여기 들어오는 resized_image 는 fixed_size 이어야 함 (same size)\n",
    "        # 생각해보니 하나의 텐서로 mini-batch 가 구성되어야 하니 당연한 것 같기는 하네.\n",
    "        # Q. FCN 같은건 그럼 어떻게 구현하지?\n",
    "        min_after_dequeue = batch_size * 10 # recommended from cs20si \n",
    "        capacity = min_after_dequeue + batch_size * 3 # recommended from tf official docs\n",
    "        params = {\n",
    "            'tensors': [resized_image, one_hot_label],\n",
    "            'batch_size': batch_size,\n",
    "            'capacity': capacity,\n",
    "            'num_threads': 1,\n",
    "            'allow_smaller_final_batch': True\n",
    "        }\n",
    "        \n",
    "        if shuffle:\n",
    "            params['min_after_dequeue'] = min_after_dequeue\n",
    "            images, labels = tf.train.shuffle_batch(**params)\n",
    "        else:\n",
    "            images, labels = tf.train.batch(**params)\n",
    "        \n",
    "#             images, labels = tf.train.shuffle_batch(\n",
    "#                 [resized_image, one_hot_label],\n",
    "#                 batch_size=batch_size,\n",
    "#                 capacity=capacity,\n",
    "#                 num_threads=1,\n",
    "#                 min_after_dequeue=min_after_dequeue,\n",
    "#                 allow_smaller_final_batch=True)\n",
    "\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_nets(tfrecords_fn, training, batch_size, batch_shuffle=True):\n",
    "    with tf.variable_scope(\"build_nets\"):\n",
    "        X, y = get_batch(tfrecords_fn, batch_size=batch_size, shuffle=batch_shuffle)\n",
    "\n",
    "        net = X\n",
    "        n_filters = 32\n",
    "        bn_param = {'is_training': training, 'scale': True, 'decay': 0.99}\n",
    "        with slim.arg_scope([slim.conv2d], kernel_size=[3,3],\n",
    "                            normalizer_fn=slim.batch_norm, normalizer_params=bn_param):\n",
    "            for _ in range(3):\n",
    "                net = slim.conv2d(net, n_filters)\n",
    "                net = slim.conv2d(net, n_filters)\n",
    "                net = slim.max_pool2d(net, kernel_size=[2,2], padding='same')\n",
    "                net = slim.dropout(net, 0.7, is_training=training)\n",
    "                n_filters *= 2\n",
    "\n",
    "        flat = slim.flatten(net)\n",
    "        logits = slim.fully_connected(flat, 5, activation_fn=None)\n",
    "        with tf.variable_scope('softmax'):\n",
    "            prob = tf.nn.softmax(logits)\n",
    "\n",
    "        with tf.variable_scope('accuracy'):\n",
    "            correct = tf.equal(tf.argmax(logits, axis=1), tf.argmax(y, axis=1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        with tf.variable_scope('loss'):\n",
    "            loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "            loss = tf.reduce_mean(loss)\n",
    "\n",
    "        # must do this even with slim\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            train_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "\n",
    "        tf.summary.scalar(\"loss\", loss)\n",
    "        tf.summary.scalar(\"accuracy\", accuracy)\n",
    "        \n",
    "        # heavy operation ...\n",
    "#         for var in tf.trainable_variables():\n",
    "#             tf.summary.histogram(var.name.replace(\":\", \"_\"), var)\n",
    "        summary_op = tf.summary.merge_all()\n",
    "\n",
    "        return accuracy, loss, train_op, summary_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# batch_size 를 여기서 정하는 게 이상한가...\n",
    "batch_size = 128\n",
    "accuracy, loss, train_op, summary_op = build_nets(tfrecords_train_fn, training=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 33.12%, loss: 6.0187 - 3s\n",
      "epoch: 1, acc: 28.22%, loss: 3.6577 - 3s\n",
      "epoch: 2, acc: 29.47%, loss: 2.7814 - 3s\n",
      "epoch: 3, acc: 30.56%, loss: 2.3881 - 3s\n",
      "epoch: 4, acc: 29.62%, loss: 2.2485 - 3s\n",
      "epoch: 5, acc: 30.00%, loss: 2.2522 - 3s\n",
      "epoch: 6, acc: 28.50%, loss: 2.2389 - 3s\n",
      "epoch: 7, acc: 32.62%, loss: 1.9379 - 3s\n",
      "epoch: 8, acc: 38.94%, loss: 1.7381 - 3s\n",
      "epoch: 9, acc: 42.47%, loss: 1.6688 - 3s\n",
      "epoch: 10, acc: 43.47%, loss: 1.8308 - 3s\n",
      "epoch: 11, acc: 44.09%, loss: 1.6163 - 3s\n",
      "epoch: 12, acc: 46.53%, loss: 1.5229 - 3s\n",
      "epoch: 13, acc: 48.12%, loss: 1.5584 - 3s\n",
      "epoch: 14, acc: 43.72%, loss: 1.5569 - 3s\n",
      "epoch: 15, acc: 42.53%, loss: 1.5322 - 3s\n",
      "epoch: 16, acc: 45.12%, loss: 1.3845 - 3s\n",
      "epoch: 17, acc: 46.56%, loss: 1.3609 - 3s\n",
      "epoch: 18, acc: 50.00%, loss: 1.2463 - 3s\n",
      "epoch: 19, acc: 50.06%, loss: 1.2234 - 3s\n",
      "epoch: 20, acc: 51.53%, loss: 1.2144 - 3s\n",
      "epoch: 21, acc: 52.72%, loss: 1.2221 - 3s\n",
      "epoch: 22, acc: 50.44%, loss: 1.2387 - 3s\n",
      "epoch: 23, acc: 52.28%, loss: 1.1629 - 3s\n",
      "epoch: 24, acc: 55.91%, loss: 1.0918 - 3s\n",
      "epoch: 25, acc: 56.75%, loss: 1.0898 - 3s\n",
      "epoch: 26, acc: 56.09%, loss: 1.0838 - 3s\n",
      "epoch: 27, acc: 57.97%, loss: 1.0548 - 3s\n",
      "epoch: 28, acc: 59.09%, loss: 1.0214 - 3s\n",
      "epoch: 29, acc: 58.47%, loss: 1.0517 - 3s\n",
      "epoch: 30, acc: 60.38%, loss: 1.0031 - 3s\n",
      "epoch: 31, acc: 57.94%, loss: 1.0552 - 3s\n",
      "epoch: 32, acc: 60.03%, loss: 1.0011 - 3s\n",
      "epoch: 33, acc: 58.00%, loss: 1.0329 - 3s\n",
      "epoch: 34, acc: 61.00%, loss: 0.9833 - 3s\n",
      "epoch: 35, acc: 60.62%, loss: 0.9780 - 3s\n",
      "epoch: 36, acc: 60.25%, loss: 0.9942 - 3s\n",
      "epoch: 37, acc: 63.03%, loss: 0.9265 - 3s\n",
      "epoch: 38, acc: 65.12%, loss: 0.9042 - 3s\n",
      "epoch: 39, acc: 63.97%, loss: 0.9246 - 3s\n",
      "epoch: 40, acc: 65.19%, loss: 0.8982 - 3s\n",
      "epoch: 41, acc: 63.16%, loss: 0.9277 - 3s\n",
      "epoch: 42, acc: 66.03%, loss: 0.8902 - 3s\n",
      "epoch: 43, acc: 65.25%, loss: 0.8940 - 3s\n",
      "epoch: 44, acc: 66.31%, loss: 0.8597 - 3s\n",
      "epoch: 45, acc: 67.28%, loss: 0.8460 - 3s\n",
      "epoch: 46, acc: 67.75%, loss: 0.8301 - 3s\n",
      "epoch: 47, acc: 69.06%, loss: 0.8169 - 3s\n",
      "epoch: 48, acc: 68.44%, loss: 0.8139 - 3s\n",
      "epoch: 49, acc: 69.41%, loss: 0.7906 - 3s\n",
      "epoch: 50, acc: 68.62%, loss: 0.7973 - 3s\n",
      "epoch: 51, acc: 67.19%, loss: 0.8436 - 3s\n",
      "epoch: 52, acc: 67.50%, loss: 0.7996 - 3s\n",
      "epoch: 53, acc: 70.78%, loss: 0.7780 - 3s\n",
      "epoch: 54, acc: 70.44%, loss: 0.7729 - 3s\n",
      "epoch: 55, acc: 70.12%, loss: 0.7709 - 3s\n",
      "epoch: 56, acc: 71.34%, loss: 0.7577 - 3s\n",
      "epoch: 57, acc: 71.91%, loss: 0.7547 - 3s\n",
      "epoch: 58, acc: 70.53%, loss: 0.7274 - 3s\n",
      "epoch: 59, acc: 73.06%, loss: 0.7016 - 3s\n"
     ]
    }
   ],
   "source": [
    "# sess = tf.Session()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    saver = tf.train.Saver(max_to_keep=100) # None 으로 하면 안 됨\n",
    "    summary_writer = tf.summary.FileWriter(logdir='./summary/train', graph=sess.graph, flush_secs=10)\n",
    "    \n",
    "    n_epoch = 60\n",
    "    iter_per_epoch = num_train // batch_size\n",
    "\n",
    "    for i in range(n_epoch):\n",
    "        avg_acc = 0.\n",
    "        avg_loss = 0.\n",
    "        st = time.time()\n",
    "        for _ in range(iter_per_epoch):\n",
    "            _, cur_summary, cur_acc, cur_loss = sess.run([train_op, summary_op, accuracy, loss])\n",
    "            avg_acc += cur_acc\n",
    "            avg_loss += cur_loss\n",
    "            summary_writer.add_summary(cur_summary, global_step=i)\n",
    "        \n",
    "        avg_acc /= iter_per_epoch\n",
    "        avg_loss /= iter_per_epoch\n",
    "        print \"epoch: {}, acc: {:.2%}, loss: {:.4f} - {:.0f}s\".format(i, avg_acc, avg_loss, time.time()-st)\n",
    "        saver.save(sess, 'checkpoints/flower', global_step=i)\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build evaluation graph\n",
    "tf.reset_default_graph()\n",
    "accuracy, loss, train_op, summary_op = build_nets(tfrecords_test_fn, training=False, \n",
    "                                                  batch_size=num_test, batch_shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== checkpoints ===\n",
      "model_checkpoint_path: \"checkpoints/flower-59\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-0\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-1\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-2\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-3\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-4\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-5\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-6\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-7\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-8\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-9\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-10\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-11\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-12\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-13\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-14\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-15\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-16\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-17\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-18\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-19\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-20\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-21\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-22\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-23\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-24\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-25\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-26\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-27\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-28\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-29\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-30\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-31\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-32\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-33\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-34\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-35\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-36\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-37\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-38\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-39\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-40\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-41\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-42\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-43\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-44\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-45\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-46\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-47\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-48\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-49\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-50\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-51\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-52\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-53\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-54\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-55\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-56\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-57\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-58\"\n",
      "all_model_checkpoint_paths: \"checkpoints/flower-59\"\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-0\n",
      "0 0.266484 56.0884\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-1\n",
      "1 0.25 10.3407\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-2\n",
      "2 0.260989 2.73511\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-3\n",
      "3 0.315934 1.73242\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-4\n",
      "4 0.252747 1.6078\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-5\n",
      "5 0.225275 1.76091\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-6\n",
      "6 0.241758 2.06108\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-7\n",
      "7 0.282967 2.03493\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-8\n",
      "8 0.252747 1.85455\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-9\n",
      "9 0.31044 1.6585\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-10\n",
      "10 0.285714 1.67825\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-11\n",
      "11 0.354396 1.59023\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-12\n",
      "12 0.335165 1.91485\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-13\n",
      "13 0.307692 1.84734\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-14\n",
      "14 0.318681 1.84476\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-15\n",
      "15 0.376374 1.74888\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-16\n",
      "16 0.370879 1.54684\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-17\n",
      "17 0.379121 1.47075\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-18\n",
      "18 0.401099 1.36516\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-19\n",
      "19 0.42033 1.31481\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-20\n",
      "20 0.475275 1.27469\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-21\n",
      "21 0.409341 1.6732\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-22\n",
      "22 0.519231 1.17941\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-23\n",
      "23 0.568681 1.02226\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-24\n",
      "24 0.565934 1.10355\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-25\n",
      "25 0.571429 1.02756\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-26\n",
      "26 0.582418 0.967265\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-27\n",
      "27 0.546703 1.12055\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-28\n",
      "28 0.596154 1.0822\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-29\n",
      "29 0.626374 0.914549\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-30\n",
      "30 0.563187 1.06371\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-31\n",
      "31 0.554945 1.13054\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-32\n",
      "32 0.557692 1.24319\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-33\n",
      "33 0.571429 1.23232\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-34\n",
      "34 0.532967 1.13326\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-35\n",
      "35 0.618132 0.955677\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-36\n",
      "36 0.57967 1.12994\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-37\n",
      "37 0.662088 0.894928\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-38\n",
      "38 0.472527 1.28578\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-39\n",
      "39 0.549451 1.06465\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-40\n",
      "40 0.401099 2.17183\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-41\n",
      "41 0.516484 1.24436\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-42\n",
      "42 0.574176 1.13862\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-43\n",
      "43 0.615385 1.04581\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-44\n",
      "44 0.60989 1.03224\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-45\n",
      "45 0.598901 1.03503\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-46\n",
      "46 0.67033 0.857037\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-47\n",
      "47 0.651099 0.892714\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-48\n",
      "48 0.546703 1.39183\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-49\n",
      "49 0.587912 1.04102\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-50\n",
      "50 0.662088 0.887298\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-51\n",
      "51 0.623626 1.10439\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-52\n",
      "52 0.642857 0.908541\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-53\n",
      "53 0.620879 1.04487\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-54\n",
      "54 0.634615 1.02104\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-55\n",
      "55 0.626374 1.03097\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-56\n",
      "56 0.532967 1.34597\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-57\n",
      "57 0.634615 0.93719\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-58\n",
      "58 0.664835 0.859121\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/flower-59\n",
      "59 0.662088 0.950895\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver() \n",
    "    ckpt = tf.train.get_checkpoint_state(\"checkpoints/\")\n",
    "    print \"=== checkpoints ===\"\n",
    "    print ckpt\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    summary_writer = tf.summary.FileWriter(logdir='./summary/test', graph=sess.graph, flush_secs=10)\n",
    "    \n",
    "    for v in ckpt.all_model_checkpoint_paths:\n",
    "        saver.restore(sess, v)\n",
    "        global_step = v.split('/')[-1].split('-')[-1]\n",
    "        \n",
    "#         n_iter = int(np.ceil(num_test/800.))\n",
    "\n",
    "        cur_summary, cur_acc, cur_loss = sess.run([summary_op, accuracy, loss])\n",
    "        summary_writer.add_summary(cur_summary, global_step=global_step)\n",
    "\n",
    "        print global_step, cur_acc, cur_loss\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [n.name for n in tf.get_default_graph().as_graph_def().node]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 - tf.latest",
   "language": "python",
   "name": "python2-tf-latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
