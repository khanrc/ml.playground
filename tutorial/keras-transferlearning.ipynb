{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning (fine-tuning)\n",
    "\n",
    "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "\n",
    "* flower dataset 으로 해 보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, BatchNormalization, Activation, MaxPooling2D, Dense, Flatten, Dropout, Input\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.6'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model_functional(input_shape, output_units):\n",
    "    input_tensor = Input(input_shape)\n",
    "    net = input_tensor\n",
    "    n_filters = 32\n",
    "\n",
    "    for _ in range(3):\n",
    "        net = Conv2D(n_filters, [3,3], padding='same', use_bias=False)(net)\n",
    "        net = BatchNormalization()(net)\n",
    "        net = Activation('relu')(net)\n",
    "        net = Conv2D(n_filters, [3,3], padding='same', use_bias=False)(net)\n",
    "        net = BatchNormalization()(net)\n",
    "        net = Activation('relu')(net)\n",
    "        net = MaxPooling2D(padding='same')(net)\n",
    "        net = Dropout(0.3)(net)\n",
    "        \n",
    "        n_filters *= 2\n",
    "\n",
    "    net = Flatten()(net)\n",
    "    net = Dense(output_units, activation='softmax')(net)\n",
    "\n",
    "    model = Model(input_tensor, net)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build net\n",
    "# without data augmentation\n",
    "datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3306 images belonging to 5 classes.\n",
      "Found 364 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "train_generator = datagen.flow_from_directory(directory='./data/flower_photos/train/', \n",
    "                                              target_size=[64, 64], \n",
    "                                              batch_size=batch_size)\n",
    "test_generator = datagen.flow_from_directory(directory='./data/flower_photos/test/',\n",
    "                                             target_size=[64, 64],\n",
    "                                             batch_size=batch_size)\n",
    "model = build_model_functional([64, 64, 3], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "5s - loss: 2.1803 - acc: 0.4106 - val_loss: 1.6292 - val_acc: 0.2305\n",
      "Epoch 2/60\n",
      "4s - loss: 1.2412 - acc: 0.5505 - val_loss: 1.9736 - val_acc: 0.2383\n",
      "Epoch 3/60\n",
      "5s - loss: 1.1315 - acc: 0.5924 - val_loss: 2.3536 - val_acc: 0.2383\n",
      "Epoch 4/60\n",
      "4s - loss: 1.0586 - acc: 0.6243 - val_loss: 2.6283 - val_acc: 0.2383\n",
      "Epoch 5/60\n",
      "4s - loss: 0.9611 - acc: 0.6432 - val_loss: 2.6265 - val_acc: 0.2500\n",
      "Epoch 6/60\n",
      "4s - loss: 0.9264 - acc: 0.6592 - val_loss: 3.0631 - val_acc: 0.2578\n",
      "Epoch 7/60\n",
      "4s - loss: 0.8680 - acc: 0.6784 - val_loss: 3.3860 - val_acc: 0.2266\n",
      "Epoch 8/60\n",
      "4s - loss: 0.7874 - acc: 0.7192 - val_loss: 4.1670 - val_acc: 0.2422\n",
      "Epoch 9/60\n",
      "4s - loss: 0.7961 - acc: 0.7081 - val_loss: 3.3584 - val_acc: 0.2266\n",
      "Epoch 10/60\n",
      "5s - loss: 0.7152 - acc: 0.7389 - val_loss: 4.0701 - val_acc: 0.2500\n",
      "Epoch 11/60\n",
      "4s - loss: 0.7435 - acc: 0.7263 - val_loss: 3.7318 - val_acc: 0.2109\n",
      "Epoch 12/60\n",
      "4s - loss: 0.6426 - acc: 0.7662 - val_loss: 3.4272 - val_acc: 0.2812\n",
      "Epoch 13/60\n",
      "4s - loss: 0.6285 - acc: 0.7801 - val_loss: 3.5203 - val_acc: 0.2227\n",
      "Epoch 14/60\n",
      "4s - loss: 0.6565 - acc: 0.7495 - val_loss: 2.8217 - val_acc: 0.2734\n",
      "Epoch 15/60\n",
      "4s - loss: 0.5848 - acc: 0.7833 - val_loss: 3.5484 - val_acc: 0.2539\n",
      "Epoch 16/60\n",
      "4s - loss: 0.5373 - acc: 0.8085 - val_loss: 2.9401 - val_acc: 0.2969\n",
      "Epoch 17/60\n",
      "4s - loss: 0.5121 - acc: 0.8116 - val_loss: 3.1672 - val_acc: 0.2852\n",
      "Epoch 18/60\n",
      "4s - loss: 0.5193 - acc: 0.8099 - val_loss: 2.2687 - val_acc: 0.4297\n",
      "Epoch 19/60\n",
      "5s - loss: 0.4858 - acc: 0.8142 - val_loss: 1.5401 - val_acc: 0.5156\n",
      "Epoch 20/60\n",
      "4s - loss: 0.4882 - acc: 0.8270 - val_loss: 2.5574 - val_acc: 0.4297\n",
      "Epoch 21/60\n",
      "4s - loss: 0.4244 - acc: 0.8474 - val_loss: 1.4625 - val_acc: 0.5586\n",
      "Epoch 22/60\n",
      "4s - loss: 0.4360 - acc: 0.8463 - val_loss: 1.8210 - val_acc: 0.4766\n",
      "Epoch 23/60\n",
      "4s - loss: 0.3594 - acc: 0.8602 - val_loss: 1.7230 - val_acc: 0.5352\n",
      "Epoch 24/60\n",
      "4s - loss: 0.3696 - acc: 0.8625 - val_loss: 1.0744 - val_acc: 0.6602\n",
      "Epoch 25/60\n",
      "4s - loss: 0.3375 - acc: 0.8780 - val_loss: 2.2202 - val_acc: 0.5078\n",
      "Epoch 26/60\n",
      "5s - loss: 0.3408 - acc: 0.8780 - val_loss: 1.2334 - val_acc: 0.6523\n",
      "Epoch 27/60\n",
      "4s - loss: 0.2972 - acc: 0.8931 - val_loss: 1.5570 - val_acc: 0.5859\n",
      "Epoch 28/60\n",
      "5s - loss: 0.2872 - acc: 0.8977 - val_loss: 1.4370 - val_acc: 0.6445\n",
      "Epoch 29/60\n",
      "4s - loss: 0.2714 - acc: 0.8980 - val_loss: 1.2481 - val_acc: 0.6680\n",
      "Epoch 30/60\n",
      "4s - loss: 0.2692 - acc: 0.9012 - val_loss: 1.1648 - val_acc: 0.7188\n",
      "Epoch 31/60\n",
      "4s - loss: 0.2618 - acc: 0.9024 - val_loss: 1.1610 - val_acc: 0.6914\n",
      "Epoch 32/60\n",
      "4s - loss: 0.2141 - acc: 0.9218 - val_loss: 1.0097 - val_acc: 0.7070\n",
      "Epoch 33/60\n",
      "4s - loss: 0.2014 - acc: 0.9255 - val_loss: 1.3386 - val_acc: 0.6328\n",
      "Epoch 34/60\n",
      "4s - loss: 0.1820 - acc: 0.9357 - val_loss: 1.5122 - val_acc: 0.6250\n",
      "Epoch 35/60\n",
      "4s - loss: 0.1750 - acc: 0.9386 - val_loss: 1.5233 - val_acc: 0.6719\n",
      "Epoch 36/60\n",
      "4s - loss: 0.2372 - acc: 0.9102 - val_loss: 1.3426 - val_acc: 0.6953\n",
      "Epoch 37/60\n",
      "4s - loss: 0.1850 - acc: 0.9339 - val_loss: 1.5540 - val_acc: 0.6484\n",
      "Epoch 38/60\n",
      "5s - loss: 0.1576 - acc: 0.9410 - val_loss: 1.4519 - val_acc: 0.6602\n",
      "Epoch 39/60\n",
      "5s - loss: 0.1393 - acc: 0.9490 - val_loss: 1.0877 - val_acc: 0.7188\n",
      "Epoch 40/60\n",
      "4s - loss: 0.1768 - acc: 0.9372 - val_loss: 1.1663 - val_acc: 0.7109\n",
      "Epoch 41/60\n",
      "5s - loss: 0.1459 - acc: 0.9494 - val_loss: 1.4831 - val_acc: 0.6719\n",
      "Epoch 42/60\n",
      "4s - loss: 0.1495 - acc: 0.9491 - val_loss: 1.5787 - val_acc: 0.6797\n",
      "Epoch 43/60\n",
      "4s - loss: 0.1549 - acc: 0.9405 - val_loss: 1.1257 - val_acc: 0.6914\n",
      "Epoch 44/60\n",
      "5s - loss: 0.1234 - acc: 0.9533 - val_loss: 1.0624 - val_acc: 0.7188\n",
      "Epoch 45/60\n",
      "4s - loss: 0.1226 - acc: 0.9594 - val_loss: 1.1535 - val_acc: 0.7148\n",
      "Epoch 46/60\n",
      "4s - loss: 0.1445 - acc: 0.9499 - val_loss: 1.1944 - val_acc: 0.7148\n",
      "Epoch 47/60\n",
      "5s - loss: 0.1078 - acc: 0.9611 - val_loss: 1.3907 - val_acc: 0.7070\n",
      "Epoch 48/60\n",
      "4s - loss: 0.0896 - acc: 0.9695 - val_loss: 1.2751 - val_acc: 0.6953\n",
      "Epoch 49/60\n",
      "4s - loss: 0.0885 - acc: 0.9702 - val_loss: 1.5293 - val_acc: 0.6523\n",
      "Epoch 50/60\n",
      "4s - loss: 0.0896 - acc: 0.9683 - val_loss: 1.6318 - val_acc: 0.6328\n",
      "Epoch 51/60\n",
      "5s - loss: 0.0874 - acc: 0.9696 - val_loss: 1.1775 - val_acc: 0.7188\n",
      "Epoch 52/60\n",
      "5s - loss: 0.0758 - acc: 0.9717 - val_loss: 1.2133 - val_acc: 0.7461\n",
      "Epoch 53/60\n",
      "4s - loss: 0.0743 - acc: 0.9753 - val_loss: 1.3706 - val_acc: 0.6953\n",
      "Epoch 54/60\n",
      "4s - loss: 0.0776 - acc: 0.9739 - val_loss: 1.3943 - val_acc: 0.7461\n",
      "Epoch 55/60\n",
      "5s - loss: 0.0800 - acc: 0.9734 - val_loss: 2.1033 - val_acc: 0.6484\n",
      "Epoch 56/60\n",
      "4s - loss: 0.0560 - acc: 0.9835 - val_loss: 1.4841 - val_acc: 0.6758\n",
      "Epoch 57/60\n",
      "4s - loss: 0.0644 - acc: 0.9764 - val_loss: 1.6759 - val_acc: 0.6523\n",
      "Epoch 58/60\n",
      "4s - loss: 0.0569 - acc: 0.9804 - val_loss: 1.3948 - val_acc: 0.7305\n",
      "Epoch 59/60\n",
      "5s - loss: 0.0735 - acc: 0.9751 - val_loss: 1.9761 - val_acc: 0.6797\n",
      "Epoch 60/60\n",
      "4s - loss: 0.0817 - acc: 0.9736 - val_loss: 1.4074 - val_acc: 0.7148\n"
     ]
    }
   ],
   "source": [
    "result = model.fit_generator(generator=train_generator,\n",
    "                             steps_per_epoch=3306//batch_size,\n",
    "                             epochs=60,\n",
    "                             validation_data=test_generator,\n",
    "                             validation_steps=364//batch_size,\n",
    "                             verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.06%\n"
     ]
    }
   ],
   "source": [
    "print \"{:.2%}\".format(np.average(result.history['val_acc'][-5:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 - tf.latest",
   "language": "python",
   "name": "python2-tf-latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
