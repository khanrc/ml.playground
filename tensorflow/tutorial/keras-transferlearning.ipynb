{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning (fine-tuning)\n",
    "\n",
    "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "\n",
    "* flower dataset 으로 해 보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Without data augmentation + epoch 60, batch size 32\n",
    "    * Scratch: 70.54%\n",
    "    * VGG16: 83.39%\n",
    "    * InceptionV3: 72.92%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* With data augmentation + epoch 60, batch size 32\n",
    "    * Scratch: 69.58%\n",
    "    * VGG16: 83.86%\n",
    "    * InceptionV3: 76.99%\n",
    "    * InceptionV3 + slim hyperparams: 83.13% (diff epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, BatchNormalization, Activation, MaxPooling2D, Dense, Flatten, Dropout, Input\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.6'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_shape = [128, 128, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting datagenerator\n",
    "\n",
    "* this setting should be fair to three model - learning from scratch, transfer learning from VGG16, and transfer learning from InceptionV3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# without data augmentation\n",
    "naive_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# with data augmentation\n",
    "distort_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                     shear_range=0.2,\n",
    "                                     zoom_range=0.2,\n",
    "                                     horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# 설정 바꿔주기 편하게 함수로 쓰자\n",
    "# 생각해보니 의미없네...\n",
    "def get_datagen_flow_from_dir(training):\n",
    "    if training:\n",
    "        return distort_datagen.flow_from_directory(directory='./data/flower_photos/train/', \n",
    "                                                   target_size=image_shape[:2], \n",
    "                                                   batch_size=batch_size)\n",
    "    else:\n",
    "        return naive_datagen.flow_from_directory(directory='./data/flower_photos/test/',\n",
    "                                                 target_size=image_shape[:2],\n",
    "                                                 batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3306 images belonging to 5 classes.\n",
      "Found 364 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = get_datagen_flow_from_dir(training=True)\n",
    "test_generator = get_datagen_flow_from_dir(training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model_functional(input_shape, output_units):\n",
    "    input_tensor = Input(input_shape)\n",
    "    net = input_tensor\n",
    "    n_filters = 32\n",
    "\n",
    "    for _ in range(3):\n",
    "        net = Conv2D(n_filters, [3,3], padding='same', use_bias=False)(net)\n",
    "        net = BatchNormalization()(net)\n",
    "        net = Activation('relu')(net)\n",
    "        net = Conv2D(n_filters, [3,3], padding='same', use_bias=False)(net)\n",
    "        net = BatchNormalization()(net)\n",
    "        net = Activation('relu')(net)\n",
    "        net = MaxPooling2D(padding='same')(net)\n",
    "        net = Dropout(0.3)(net)\n",
    "        \n",
    "        n_filters *= 2\n",
    "\n",
    "    net = Flatten()(net)\n",
    "    net = Dense(output_units, activation='softmax')(net)\n",
    "\n",
    "    model = Model(input_tensor, net)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = build_model_functional(image_shape, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "12s - loss: 7.6030 - acc: 0.3419 - val_loss: 7.3710 - val_acc: 0.2415\n",
      "Epoch 2/60\n",
      "11s - loss: 3.5879 - acc: 0.4339 - val_loss: 3.4401 - val_acc: 0.1867\n",
      "Epoch 3/60\n",
      "11s - loss: 3.0145 - acc: 0.4657 - val_loss: 1.8344 - val_acc: 0.3283\n",
      "Epoch 4/60\n",
      "11s - loss: 2.6832 - acc: 0.5044 - val_loss: 1.9863 - val_acc: 0.3976\n",
      "Epoch 5/60\n",
      "11s - loss: 2.2068 - acc: 0.5493 - val_loss: 2.4137 - val_acc: 0.5723\n",
      "Epoch 6/60\n",
      "11s - loss: 2.1647 - acc: 0.5389 - val_loss: 1.8236 - val_acc: 0.5361\n",
      "Epoch 7/60\n",
      "11s - loss: 1.9690 - acc: 0.5791 - val_loss: 3.2194 - val_acc: 0.3946\n",
      "Epoch 8/60\n",
      "11s - loss: 1.8541 - acc: 0.5768 - val_loss: 2.1677 - val_acc: 0.5512\n",
      "Epoch 9/60\n",
      "11s - loss: 1.8348 - acc: 0.5885 - val_loss: 3.0305 - val_acc: 0.4639\n",
      "Epoch 10/60\n",
      "11s - loss: 1.7405 - acc: 0.6032 - val_loss: 1.3072 - val_acc: 0.5572\n",
      "Epoch 11/60\n",
      "11s - loss: 1.5155 - acc: 0.6211 - val_loss: 1.0913 - val_acc: 0.6446\n",
      "Epoch 12/60\n",
      "11s - loss: 1.2111 - acc: 0.6226 - val_loss: 1.0123 - val_acc: 0.6386\n",
      "Epoch 13/60\n",
      "11s - loss: 1.1619 - acc: 0.6368 - val_loss: 1.1906 - val_acc: 0.6175\n",
      "Epoch 14/60\n",
      "11s - loss: 0.9657 - acc: 0.6561 - val_loss: 0.8513 - val_acc: 0.6807\n",
      "Epoch 15/60\n",
      "11s - loss: 0.8999 - acc: 0.6667 - val_loss: 0.9115 - val_acc: 0.6958\n",
      "Epoch 16/60\n",
      "10s - loss: 0.8481 - acc: 0.6958 - val_loss: 0.8619 - val_acc: 0.7078\n",
      "Epoch 17/60\n",
      "11s - loss: 0.8373 - acc: 0.6803 - val_loss: 0.8869 - val_acc: 0.6566\n",
      "Epoch 18/60\n",
      "11s - loss: 0.8049 - acc: 0.7084 - val_loss: 3.8379 - val_acc: 0.3434\n",
      "Epoch 19/60\n",
      "11s - loss: 0.8047 - acc: 0.6953 - val_loss: 0.7355 - val_acc: 0.7380\n",
      "Epoch 20/60\n",
      "11s - loss: 0.7576 - acc: 0.7186 - val_loss: 0.7559 - val_acc: 0.7410\n",
      "Epoch 21/60\n",
      "11s - loss: 0.7534 - acc: 0.7169 - val_loss: 0.8158 - val_acc: 0.7078\n",
      "Epoch 22/60\n",
      "11s - loss: 0.7302 - acc: 0.7240 - val_loss: 0.7649 - val_acc: 0.7380\n",
      "Epoch 23/60\n",
      "11s - loss: 0.7383 - acc: 0.7274 - val_loss: 0.8553 - val_acc: 0.7108\n",
      "Epoch 24/60\n",
      "11s - loss: 0.6997 - acc: 0.7379 - val_loss: 0.9299 - val_acc: 0.6898\n",
      "Epoch 25/60\n",
      "11s - loss: 0.7031 - acc: 0.7358 - val_loss: 0.7046 - val_acc: 0.7681\n",
      "Epoch 26/60\n",
      "10s - loss: 0.6979 - acc: 0.7376 - val_loss: 0.8761 - val_acc: 0.6898\n",
      "Epoch 27/60\n",
      "11s - loss: 0.6937 - acc: 0.7464 - val_loss: 0.8115 - val_acc: 0.7169\n",
      "Epoch 28/60\n",
      "11s - loss: 0.6453 - acc: 0.7575 - val_loss: 1.3812 - val_acc: 0.5994\n",
      "Epoch 29/60\n",
      "11s - loss: 0.6269 - acc: 0.7675 - val_loss: 0.8658 - val_acc: 0.6958\n",
      "Epoch 30/60\n",
      "11s - loss: 0.6732 - acc: 0.7526 - val_loss: 0.6795 - val_acc: 0.7289\n",
      "Epoch 31/60\n",
      "11s - loss: 0.5923 - acc: 0.7743 - val_loss: 0.7745 - val_acc: 0.7259\n",
      "Epoch 32/60\n",
      "11s - loss: 0.6075 - acc: 0.7729 - val_loss: 1.8209 - val_acc: 0.5181\n",
      "Epoch 33/60\n",
      "11s - loss: 0.6028 - acc: 0.7702 - val_loss: 0.7781 - val_acc: 0.7289\n",
      "Epoch 34/60\n",
      "11s - loss: 0.5946 - acc: 0.7818 - val_loss: 0.8495 - val_acc: 0.6837\n",
      "Epoch 35/60\n",
      "11s - loss: 0.5965 - acc: 0.7761 - val_loss: 0.7893 - val_acc: 0.7289\n",
      "Epoch 36/60\n",
      "11s - loss: 0.5706 - acc: 0.7890 - val_loss: 0.8499 - val_acc: 0.7108\n",
      "Epoch 37/60\n",
      "11s - loss: 0.5755 - acc: 0.7846 - val_loss: 0.5941 - val_acc: 0.7861\n",
      "Epoch 38/60\n",
      "11s - loss: 0.5476 - acc: 0.8030 - val_loss: 0.7491 - val_acc: 0.7169\n",
      "Epoch 39/60\n",
      "11s - loss: 0.5346 - acc: 0.7959 - val_loss: 0.7249 - val_acc: 0.7349\n",
      "Epoch 40/60\n",
      "11s - loss: 0.5325 - acc: 0.8071 - val_loss: 0.6762 - val_acc: 0.7651\n",
      "Epoch 41/60\n",
      "11s - loss: 0.5056 - acc: 0.8118 - val_loss: 0.7313 - val_acc: 0.7410\n",
      "Epoch 42/60\n",
      "11s - loss: 0.5271 - acc: 0.8013 - val_loss: 0.7295 - val_acc: 0.7139\n",
      "Epoch 43/60\n",
      "11s - loss: 0.5531 - acc: 0.8026 - val_loss: 1.0117 - val_acc: 0.6476\n",
      "Epoch 44/60\n",
      "11s - loss: 0.4907 - acc: 0.8164 - val_loss: 0.6664 - val_acc: 0.7711\n",
      "Epoch 45/60\n",
      "11s - loss: 0.4818 - acc: 0.8183 - val_loss: 0.9508 - val_acc: 0.6416\n",
      "Epoch 46/60\n",
      "11s - loss: 0.4688 - acc: 0.8307 - val_loss: 0.7435 - val_acc: 0.7349\n",
      "Epoch 47/60\n",
      "11s - loss: 0.4916 - acc: 0.8200 - val_loss: 0.5632 - val_acc: 0.7952\n",
      "Epoch 48/60\n",
      "11s - loss: 0.4641 - acc: 0.8291 - val_loss: 0.6965 - val_acc: 0.7560\n",
      "Epoch 49/60\n",
      "11s - loss: 0.4545 - acc: 0.8290 - val_loss: 0.5943 - val_acc: 0.7801\n",
      "Epoch 50/60\n",
      "11s - loss: 0.4640 - acc: 0.8328 - val_loss: 0.6268 - val_acc: 0.7651\n",
      "Epoch 51/60\n",
      "11s - loss: 0.4553 - acc: 0.8278 - val_loss: 0.8101 - val_acc: 0.7048\n",
      "Epoch 52/60\n",
      "11s - loss: 0.4381 - acc: 0.8357 - val_loss: 0.6302 - val_acc: 0.7620\n",
      "Epoch 53/60\n",
      "11s - loss: 0.4075 - acc: 0.8473 - val_loss: 0.6474 - val_acc: 0.7560\n",
      "Epoch 54/60\n",
      "11s - loss: 0.4218 - acc: 0.8430 - val_loss: 0.7688 - val_acc: 0.7470\n",
      "Epoch 55/60\n",
      "11s - loss: 0.4055 - acc: 0.8478 - val_loss: 0.6354 - val_acc: 0.7771\n",
      "Epoch 56/60\n",
      "11s - loss: 0.4323 - acc: 0.8441 - val_loss: 0.7145 - val_acc: 0.7620\n",
      "Epoch 57/60\n",
      "11s - loss: 0.3827 - acc: 0.8546 - val_loss: 0.6415 - val_acc: 0.7620\n",
      "Epoch 58/60\n",
      "11s - loss: 0.5526 - acc: 0.8164 - val_loss: 1.7428 - val_acc: 0.4578\n",
      "Epoch 59/60\n",
      "11s - loss: 0.4458 - acc: 0.8362 - val_loss: 0.7186 - val_acc: 0.7289\n",
      "Epoch 60/60\n",
      "11s - loss: 0.3802 - acc: 0.8609 - val_loss: 0.6508 - val_acc: 0.7681\n"
     ]
    }
   ],
   "source": [
    "result = model.fit_generator(generator=train_generator,\n",
    "                             steps_per_epoch=train_generator.samples//batch_size,\n",
    "                             epochs=60,\n",
    "                             validation_data=test_generator,\n",
    "                             validation_steps=test_generator.samples//batch_size,\n",
    "                             verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.58%\n"
     ]
    }
   ],
   "source": [
    "print \"{:.2%}\".format(np.average(result.history['val_acc'][-5:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Weights are downloaded automatically when instantiating a model. They are stored at `~/.keras/models/.`\n",
    "model = applications.VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"vgg16/block5_pool/MaxPool:0\", shape=(?, 4, 4, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(image_shape)\n",
    "net = model(input_tensor)\n",
    "print net # check last conv block shape\n",
    "net = Flatten()(net)\n",
    "net = Dense(256, activation='relu')(net)\n",
    "net = Dropout(0.5)(net)\n",
    "net = Dense(5, activation='softmax')(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fine-tuning only last conv block + added 2 fc layers\n",
    "# for layer in model.layers:\n",
    "#     print layer.trainable\n",
    "for layer in model.layers[:-4]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(input_tensor, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# According to the tutorial, small learning rate is suitable for fine-tuning.\n",
    "# In the same context, adaptive learning rate (like adam) is inappropriate.\n",
    "# So, we use SGD with momentum.\n",
    "model.compile(optimizer=optimizers.SGD(lr=1e-4, momentum=0.9), \n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "103/103 [==============================] - 15s - loss: 1.5836 - acc: 0.3403 - val_loss: 1.2415 - val_acc: 0.5422\n",
      "Epoch 2/60\n",
      "103/103 [==============================] - 11s - loss: 1.1856 - acc: 0.5204 - val_loss: 0.9613 - val_acc: 0.6717\n",
      "Epoch 3/60\n",
      "103/103 [==============================] - 11s - loss: 0.9547 - acc: 0.6362 - val_loss: 0.8220 - val_acc: 0.7139\n",
      "Epoch 4/60\n",
      "103/103 [==============================] - 11s - loss: 0.8167 - acc: 0.7004 - val_loss: 0.7494 - val_acc: 0.7169\n",
      "Epoch 5/60\n",
      "103/103 [==============================] - 11s - loss: 0.7018 - acc: 0.7435 - val_loss: 0.6902 - val_acc: 0.7590\n",
      "Epoch 6/60\n",
      "103/103 [==============================] - 11s - loss: 0.6443 - acc: 0.7646 - val_loss: 0.6098 - val_acc: 0.7771\n",
      "Epoch 7/60\n",
      "103/103 [==============================] - 11s - loss: 0.5986 - acc: 0.7834 - val_loss: 0.6099 - val_acc: 0.7801\n",
      "Epoch 8/60\n",
      "103/103 [==============================] - 11s - loss: 0.5679 - acc: 0.7939 - val_loss: 0.5898 - val_acc: 0.7801\n",
      "Epoch 9/60\n",
      "103/103 [==============================] - 11s - loss: 0.5503 - acc: 0.7993 - val_loss: 0.5309 - val_acc: 0.8253\n",
      "Epoch 10/60\n",
      "103/103 [==============================] - 11s - loss: 0.4798 - acc: 0.8223 - val_loss: 0.4983 - val_acc: 0.8223\n",
      "Epoch 11/60\n",
      "103/103 [==============================] - 11s - loss: 0.4887 - acc: 0.8191 - val_loss: 0.5523 - val_acc: 0.8072\n",
      "Epoch 12/60\n",
      "103/103 [==============================] - 11s - loss: 0.4686 - acc: 0.8312 - val_loss: 0.5276 - val_acc: 0.8072\n",
      "Epoch 13/60\n",
      "103/103 [==============================] - 11s - loss: 0.4512 - acc: 0.8391 - val_loss: 0.5094 - val_acc: 0.8193\n",
      "Epoch 14/60\n",
      "103/103 [==============================] - 11s - loss: 0.4292 - acc: 0.8407 - val_loss: 0.4892 - val_acc: 0.8193\n",
      "Epoch 15/60\n",
      "103/103 [==============================] - 11s - loss: 0.4302 - acc: 0.8428 - val_loss: 0.4843 - val_acc: 0.8434\n",
      "Epoch 16/60\n",
      "103/103 [==============================] - 11s - loss: 0.3875 - acc: 0.8622 - val_loss: 0.5529 - val_acc: 0.8223\n",
      "Epoch 17/60\n",
      "103/103 [==============================] - 11s - loss: 0.3752 - acc: 0.8651 - val_loss: 0.5048 - val_acc: 0.8283\n",
      "Epoch 18/60\n",
      "103/103 [==============================] - 11s - loss: 0.3758 - acc: 0.8679 - val_loss: 0.5028 - val_acc: 0.8464\n",
      "Epoch 19/60\n",
      "103/103 [==============================] - 11s - loss: 0.3654 - acc: 0.8619 - val_loss: 0.5202 - val_acc: 0.8313\n",
      "Epoch 20/60\n",
      "103/103 [==============================] - 11s - loss: 0.3565 - acc: 0.8734 - val_loss: 0.4566 - val_acc: 0.8494\n",
      "Epoch 21/60\n",
      "103/103 [==============================] - 11s - loss: 0.3338 - acc: 0.8817 - val_loss: 0.4910 - val_acc: 0.8193\n",
      "Epoch 22/60\n",
      "103/103 [==============================] - 11s - loss: 0.3323 - acc: 0.8780 - val_loss: 0.4449 - val_acc: 0.8434\n",
      "Epoch 23/60\n",
      "103/103 [==============================] - 11s - loss: 0.3178 - acc: 0.8854 - val_loss: 0.5258 - val_acc: 0.8072\n",
      "Epoch 24/60\n",
      "103/103 [==============================] - 11s - loss: 0.3056 - acc: 0.8902 - val_loss: 0.4247 - val_acc: 0.8584\n",
      "Epoch 25/60\n",
      "103/103 [==============================] - 11s - loss: 0.3167 - acc: 0.8839 - val_loss: 0.5615 - val_acc: 0.7922\n",
      "Epoch 26/60\n",
      "103/103 [==============================] - 11s - loss: 0.3048 - acc: 0.8898 - val_loss: 0.4239 - val_acc: 0.8494\n",
      "Epoch 27/60\n",
      "103/103 [==============================] - 11s - loss: 0.2714 - acc: 0.9006 - val_loss: 0.4717 - val_acc: 0.8404\n",
      "Epoch 28/60\n",
      "103/103 [==============================] - 11s - loss: 0.2804 - acc: 0.9020 - val_loss: 0.5246 - val_acc: 0.8223\n",
      "Epoch 29/60\n",
      "103/103 [==============================] - 11s - loss: 0.2705 - acc: 0.9041 - val_loss: 0.4988 - val_acc: 0.8253\n",
      "Epoch 30/60\n",
      "103/103 [==============================] - 11s - loss: 0.2730 - acc: 0.9041 - val_loss: 0.3931 - val_acc: 0.8735\n",
      "Epoch 31/60\n",
      "103/103 [==============================] - 11s - loss: 0.2438 - acc: 0.9126 - val_loss: 0.4733 - val_acc: 0.8193\n",
      "Epoch 32/60\n",
      "103/103 [==============================] - 11s - loss: 0.2400 - acc: 0.9184 - val_loss: 0.5046 - val_acc: 0.8253\n",
      "Epoch 33/60\n",
      "103/103 [==============================] - 11s - loss: 0.2439 - acc: 0.9138 - val_loss: 0.4465 - val_acc: 0.8404\n",
      "Epoch 34/60\n",
      "103/103 [==============================] - 11s - loss: 0.2266 - acc: 0.9174 - val_loss: 0.4847 - val_acc: 0.8283\n",
      "Epoch 35/60\n",
      "103/103 [==============================] - 11s - loss: 0.2412 - acc: 0.9115 - val_loss: 0.4146 - val_acc: 0.8554\n",
      "Epoch 36/60\n",
      "103/103 [==============================] - 11s - loss: 0.2224 - acc: 0.9217 - val_loss: 0.5108 - val_acc: 0.8283\n",
      "Epoch 37/60\n",
      "103/103 [==============================] - 11s - loss: 0.2105 - acc: 0.9269 - val_loss: 0.4144 - val_acc: 0.8614\n",
      "Epoch 38/60\n",
      "103/103 [==============================] - 11s - loss: 0.2117 - acc: 0.9263 - val_loss: 0.5502 - val_acc: 0.8102\n",
      "Epoch 39/60\n",
      "103/103 [==============================] - 11s - loss: 0.2007 - acc: 0.9262 - val_loss: 0.5183 - val_acc: 0.8373\n",
      "Epoch 40/60\n",
      "103/103 [==============================] - 11s - loss: 0.2001 - acc: 0.9265 - val_loss: 0.4014 - val_acc: 0.8645\n",
      "Epoch 41/60\n",
      "103/103 [==============================] - 11s - loss: 0.2008 - acc: 0.9302 - val_loss: 0.4950 - val_acc: 0.8163\n",
      "Epoch 42/60\n",
      "103/103 [==============================] - 11s - loss: 0.1837 - acc: 0.9362 - val_loss: 0.5006 - val_acc: 0.8313\n",
      "Epoch 43/60\n",
      "103/103 [==============================] - 11s - loss: 0.1866 - acc: 0.9302 - val_loss: 0.5411 - val_acc: 0.8193\n",
      "Epoch 44/60\n",
      "103/103 [==============================] - 11s - loss: 0.1876 - acc: 0.9320 - val_loss: 0.4596 - val_acc: 0.8554\n",
      "Epoch 45/60\n",
      "103/103 [==============================] - 11s - loss: 0.1717 - acc: 0.9396 - val_loss: 0.4018 - val_acc: 0.8795\n",
      "Epoch 46/60\n",
      "103/103 [==============================] - 11s - loss: 0.1754 - acc: 0.9393 - val_loss: 0.5399 - val_acc: 0.8343\n",
      "Epoch 47/60\n",
      "103/103 [==============================] - 11s - loss: 0.1679 - acc: 0.9402 - val_loss: 0.6095 - val_acc: 0.7982\n",
      "Epoch 48/60\n",
      "103/103 [==============================] - 11s - loss: 0.1556 - acc: 0.9454 - val_loss: 0.4373 - val_acc: 0.8614\n",
      "Epoch 49/60\n",
      "103/103 [==============================] - 11s - loss: 0.1629 - acc: 0.9427 - val_loss: 0.5114 - val_acc: 0.8464\n",
      "Epoch 50/60\n",
      "103/103 [==============================] - 11s - loss: 0.1692 - acc: 0.9374 - val_loss: 0.4546 - val_acc: 0.8434\n",
      "Epoch 51/60\n",
      "103/103 [==============================] - 11s - loss: 0.1448 - acc: 0.9520 - val_loss: 0.4375 - val_acc: 0.8584\n",
      "Epoch 52/60\n",
      "103/103 [==============================] - 11s - loss: 0.1512 - acc: 0.9478 - val_loss: 0.4971 - val_acc: 0.8554\n",
      "Epoch 53/60\n",
      "103/103 [==============================] - 11s - loss: 0.1476 - acc: 0.9511 - val_loss: 0.4391 - val_acc: 0.8614\n",
      "Epoch 54/60\n",
      "103/103 [==============================] - 11s - loss: 0.1338 - acc: 0.9530 - val_loss: 0.4415 - val_acc: 0.8554\n",
      "Epoch 55/60\n",
      "103/103 [==============================] - 11s - loss: 0.1355 - acc: 0.9520 - val_loss: 0.4969 - val_acc: 0.8524\n",
      "Epoch 56/60\n",
      "103/103 [==============================] - 11s - loss: 0.1297 - acc: 0.9572 - val_loss: 0.4418 - val_acc: 0.8283\n",
      "Epoch 57/60\n",
      "103/103 [==============================] - 11s - loss: 0.1328 - acc: 0.9504 - val_loss: 0.5032 - val_acc: 0.8434\n",
      "Epoch 58/60\n",
      "103/103 [==============================] - 11s - loss: 0.1320 - acc: 0.9563 - val_loss: 0.5289 - val_acc: 0.8313\n",
      "Epoch 59/60\n",
      "103/103 [==============================] - 11s - loss: 0.1143 - acc: 0.9624 - val_loss: 0.5197 - val_acc: 0.8464\n",
      "Epoch 60/60\n",
      "103/103 [==============================] - 11s - loss: 0.1215 - acc: 0.9532 - val_loss: 0.4991 - val_acc: 0.8434\n"
     ]
    }
   ],
   "source": [
    "result = model.fit_generator(generator=train_generator,\n",
    "                             steps_per_epoch=train_generator.samples//batch_size,\n",
    "                             epochs=60,\n",
    "                             validation_data=test_generator,\n",
    "                             validation_steps=test_generator.samples//batch_size,\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.86%\n"
     ]
    }
   ],
   "source": [
    "print \"{:.2%}\".format(np.average(result.history['val_acc'][-5:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionV3\n",
    "\n",
    "* https://keras.io/applications/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"inception_v3/mixed10/concat:0\", shape=(?, 2, 2, 2048), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "base_model = applications.inception_v3.InceptionV3(weights='imagenet', include_top=False)\n",
    "# net = base_model.output\n",
    "input_tensor = Input(image_shape)\n",
    "net = base_model(input_tensor)\n",
    "print net\n",
    "net = GlobalAveragePooling2D()(net) # 2048\n",
    "net = Dense(1024, activation='relu')(net)\n",
    "net = Dense(5, activation='softmax')(net)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=net)\n",
    "\n",
    "# freeze whole base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# https://github.com/tensorflow/models/blob/master/slim/scripts/finetune_inception_v3_on_flowers.sh\n",
    "# step=1000 => epoch=10\n",
    "# model.compile(optimizer=optimizers.RMSprop(lr=0.01, decay=0.00004), \n",
    "#               loss='categorical_crossentropy', \n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "103/103 [==============================] - 12s - loss: 1.8610 - acc: 0.4410 - val_loss: 1.1102 - val_acc: 0.6175\n",
      "Epoch 2/60\n",
      "103/103 [==============================] - 11s - loss: 1.1825 - acc: 0.5651 - val_loss: 1.2819 - val_acc: 0.5512\n",
      "Epoch 3/60\n",
      "103/103 [==============================] - 11s - loss: 1.0537 - acc: 0.6047 - val_loss: 1.0720 - val_acc: 0.5934\n",
      "Epoch 4/60\n",
      "103/103 [==============================] - 11s - loss: 0.9412 - acc: 0.6413 - val_loss: 1.1903 - val_acc: 0.5994\n",
      "Epoch 5/60\n",
      "103/103 [==============================] - 11s - loss: 0.9176 - acc: 0.6526 - val_loss: 1.4740 - val_acc: 0.5241\n",
      "Epoch 6/60\n",
      "103/103 [==============================] - 11s - loss: 0.9158 - acc: 0.6697 - val_loss: 0.9568 - val_acc: 0.6386\n",
      "Epoch 7/60\n",
      "103/103 [==============================] - 11s - loss: 0.8940 - acc: 0.6688 - val_loss: 1.0204 - val_acc: 0.6355\n",
      "Epoch 8/60\n",
      "103/103 [==============================] - 11s - loss: 0.8607 - acc: 0.6794 - val_loss: 1.0836 - val_acc: 0.6476\n",
      "Epoch 9/60\n",
      "103/103 [==============================] - 11s - loss: 0.8338 - acc: 0.6839 - val_loss: 1.0837 - val_acc: 0.6506\n",
      "Epoch 10/60\n",
      "103/103 [==============================] - 11s - loss: 0.8495 - acc: 0.6842 - val_loss: 1.2784 - val_acc: 0.6054\n",
      "Epoch 11/60\n",
      "103/103 [==============================] - 11s - loss: 0.8159 - acc: 0.6982 - val_loss: 0.9824 - val_acc: 0.6928\n",
      "Epoch 12/60\n",
      "103/103 [==============================] - 11s - loss: 0.8031 - acc: 0.7011 - val_loss: 1.0472 - val_acc: 0.6777\n",
      "Epoch 13/60\n",
      "103/103 [==============================] - 11s - loss: 0.7867 - acc: 0.7021 - val_loss: 1.0644 - val_acc: 0.6807\n",
      "Epoch 14/60\n",
      "103/103 [==============================] - 11s - loss: 0.7868 - acc: 0.7179 - val_loss: 1.0195 - val_acc: 0.6657\n",
      "Epoch 15/60\n",
      "103/103 [==============================] - 11s - loss: 0.8049 - acc: 0.7051 - val_loss: 1.1650 - val_acc: 0.6627\n",
      "Epoch 16/60\n",
      "103/103 [==============================] - 11s - loss: 0.7823 - acc: 0.7135 - val_loss: 0.9814 - val_acc: 0.6777\n",
      "Epoch 17/60\n",
      "103/103 [==============================] - 11s - loss: 0.7553 - acc: 0.7248 - val_loss: 1.0471 - val_acc: 0.6657\n",
      "Epoch 18/60\n",
      "103/103 [==============================] - 11s - loss: 0.7025 - acc: 0.7439 - val_loss: 1.0467 - val_acc: 0.6446\n",
      "Epoch 19/60\n",
      "103/103 [==============================] - 11s - loss: 0.7700 - acc: 0.7217 - val_loss: 0.9822 - val_acc: 0.6898\n",
      "Epoch 20/60\n",
      "103/103 [==============================] - 11s - loss: 0.7224 - acc: 0.7319 - val_loss: 1.0463 - val_acc: 0.7048\n",
      "Epoch 21/60\n",
      "103/103 [==============================] - 11s - loss: 0.6835 - acc: 0.7544 - val_loss: 1.0325 - val_acc: 0.6687\n",
      "Epoch 22/60\n",
      "103/103 [==============================] - 11s - loss: 0.7158 - acc: 0.7417 - val_loss: 0.9538 - val_acc: 0.7108\n",
      "Epoch 23/60\n",
      "103/103 [==============================] - 11s - loss: 0.6812 - acc: 0.7512 - val_loss: 1.0558 - val_acc: 0.6958\n",
      "Epoch 24/60\n",
      "103/103 [==============================] - 11s - loss: 0.7207 - acc: 0.7441 - val_loss: 1.2502 - val_acc: 0.6145\n",
      "Epoch 25/60\n",
      "103/103 [==============================] - 11s - loss: 0.6795 - acc: 0.7604 - val_loss: 1.1103 - val_acc: 0.6717\n",
      "Epoch 26/60\n",
      "103/103 [==============================] - 11s - loss: 0.6914 - acc: 0.7490 - val_loss: 1.0874 - val_acc: 0.6747\n",
      "Epoch 27/60\n",
      "103/103 [==============================] - 11s - loss: 0.7092 - acc: 0.7493 - val_loss: 1.0202 - val_acc: 0.7169\n",
      "Epoch 28/60\n",
      "103/103 [==============================] - 11s - loss: 0.6707 - acc: 0.7484 - val_loss: 1.0373 - val_acc: 0.6566\n",
      "Epoch 29/60\n",
      "103/103 [==============================] - 11s - loss: 0.7055 - acc: 0.7479 - val_loss: 0.9513 - val_acc: 0.6958\n",
      "Epoch 30/60\n",
      "103/103 [==============================] - 11s - loss: 0.6772 - acc: 0.7571 - val_loss: 1.1489 - val_acc: 0.6867\n",
      "Epoch 31/60\n",
      "103/103 [==============================] - 11s - loss: 0.6845 - acc: 0.7543 - val_loss: 0.8489 - val_acc: 0.7410\n",
      "Epoch 32/60\n",
      "103/103 [==============================] - 11s - loss: 0.6966 - acc: 0.7519 - val_loss: 1.0855 - val_acc: 0.6627\n",
      "Epoch 33/60\n",
      "103/103 [==============================] - 11s - loss: 0.6351 - acc: 0.7671 - val_loss: 0.9299 - val_acc: 0.6837\n",
      "Epoch 34/60\n",
      "103/103 [==============================] - 11s - loss: 0.6573 - acc: 0.7720 - val_loss: 1.1782 - val_acc: 0.6837\n",
      "Epoch 35/60\n",
      "103/103 [==============================] - 11s - loss: 0.6711 - acc: 0.7705 - val_loss: 1.0668 - val_acc: 0.6657\n",
      "Epoch 36/60\n",
      "103/103 [==============================] - 11s - loss: 0.6547 - acc: 0.7690 - val_loss: 1.1074 - val_acc: 0.6928\n",
      "Epoch 37/60\n",
      "103/103 [==============================] - 11s - loss: 0.6497 - acc: 0.7902 - val_loss: 1.2647 - val_acc: 0.6446\n",
      "Epoch 38/60\n",
      "103/103 [==============================] - 11s - loss: 0.6288 - acc: 0.7847 - val_loss: 1.0328 - val_acc: 0.7139\n",
      "Epoch 39/60\n",
      "103/103 [==============================] - 11s - loss: 0.6308 - acc: 0.7802 - val_loss: 1.0439 - val_acc: 0.6807\n",
      "Epoch 40/60\n",
      "103/103 [==============================] - 11s - loss: 0.6271 - acc: 0.7830 - val_loss: 1.1984 - val_acc: 0.7018\n",
      "Epoch 41/60\n",
      "103/103 [==============================] - 11s - loss: 0.6259 - acc: 0.7778 - val_loss: 1.2415 - val_acc: 0.6867\n",
      "Epoch 42/60\n",
      "103/103 [==============================] - 11s - loss: 0.6378 - acc: 0.7834 - val_loss: 1.0131 - val_acc: 0.7048\n",
      "Epoch 43/60\n",
      "103/103 [==============================] - 11s - loss: 0.6031 - acc: 0.7875 - val_loss: 1.0975 - val_acc: 0.6566\n",
      "Epoch 44/60\n",
      "103/103 [==============================] - 11s - loss: 0.6094 - acc: 0.7837 - val_loss: 0.9508 - val_acc: 0.7229\n",
      "Epoch 45/60\n",
      "103/103 [==============================] - 11s - loss: 0.6334 - acc: 0.7826 - val_loss: 1.1740 - val_acc: 0.6627\n",
      "Epoch 46/60\n",
      "103/103 [==============================] - 11s - loss: 0.6276 - acc: 0.7834 - val_loss: 1.0622 - val_acc: 0.6807\n",
      "Epoch 47/60\n",
      "103/103 [==============================] - 11s - loss: 0.6084 - acc: 0.7924 - val_loss: 0.9082 - val_acc: 0.7169\n",
      "Epoch 48/60\n",
      "103/103 [==============================] - 11s - loss: 0.6064 - acc: 0.7941 - val_loss: 1.1417 - val_acc: 0.7048\n",
      "Epoch 49/60\n",
      "103/103 [==============================] - 11s - loss: 0.6066 - acc: 0.7959 - val_loss: 0.9916 - val_acc: 0.7380\n",
      "Epoch 50/60\n",
      "103/103 [==============================] - 11s - loss: 0.6367 - acc: 0.7895 - val_loss: 1.0928 - val_acc: 0.7018\n",
      "Epoch 51/60\n",
      "103/103 [==============================] - 11s - loss: 0.5640 - acc: 0.8000 - val_loss: 1.0442 - val_acc: 0.6747\n",
      "Epoch 52/60\n",
      "103/103 [==============================] - 11s - loss: 0.5792 - acc: 0.8033 - val_loss: 1.3066 - val_acc: 0.6596\n",
      "Epoch 53/60\n",
      "103/103 [==============================] - 11s - loss: 0.5880 - acc: 0.8015 - val_loss: 1.2238 - val_acc: 0.6627\n",
      "Epoch 54/60\n",
      "103/103 [==============================] - 11s - loss: 0.5981 - acc: 0.7972 - val_loss: 1.1291 - val_acc: 0.6807\n",
      "Epoch 55/60\n",
      "103/103 [==============================] - 11s - loss: 0.5935 - acc: 0.8017 - val_loss: 1.1021 - val_acc: 0.6777\n",
      "Epoch 56/60\n",
      "103/103 [==============================] - 11s - loss: 0.5701 - acc: 0.8034 - val_loss: 1.2861 - val_acc: 0.6807\n",
      "Epoch 57/60\n",
      "103/103 [==============================] - 11s - loss: 0.5992 - acc: 0.8045 - val_loss: 1.1688 - val_acc: 0.6898\n",
      "Epoch 58/60\n",
      "103/103 [==============================] - 11s - loss: 0.5621 - acc: 0.8067 - val_loss: 1.2454 - val_acc: 0.6837\n",
      "Epoch 59/60\n",
      "103/103 [==============================] - 11s - loss: 0.5982 - acc: 0.8033 - val_loss: 1.2971 - val_acc: 0.6446\n",
      "Epoch 60/60\n",
      "103/103 [==============================] - 11s - loss: 0.5861 - acc: 0.8036 - val_loss: 1.1181 - val_acc: 0.7229\n"
     ]
    }
   ],
   "source": [
    "result = model.fit_generator(generator=train_generator,\n",
    "                             steps_per_epoch=train_generator.samples//batch_size,\n",
    "                             epochs=60,\n",
    "                             validation_data=test_generator,\n",
    "                             validation_steps=test_generator.samples//batch_size,\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311\n"
     ]
    }
   ],
   "source": [
    "print len(model.layers[1].layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train the top 2 inception blocks.\n",
    "# if set trainable in base_model, which indicates models.layers[1], \n",
    "# so models.layers[1].layers[249:] is set to trainable=True.\n",
    "for layer in base_model.layers[249:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# https://github.com/tensorflow/models/blob/master/slim/scripts/finetune_inception_v3_on_flowers.sh\n",
    "# step=500 => epoch=5\n",
    "# model.compile(optimizer=optimizers.RMSprop(lr=0.0001, decay=0.00004), \n",
    "#               loss='categorical_crossentropy', \n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "103/103 [==============================] - 12s - loss: 0.5220 - acc: 0.8143 - val_loss: 1.1363 - val_acc: 0.6898\n",
      "Epoch 2/60\n",
      "103/103 [==============================] - 11s - loss: 0.4533 - acc: 0.8458 - val_loss: 1.2032 - val_acc: 0.6747\n",
      "Epoch 3/60\n",
      "103/103 [==============================] - 12s - loss: 0.4348 - acc: 0.8473 - val_loss: 0.9392 - val_acc: 0.7259\n",
      "Epoch 4/60\n",
      "103/103 [==============================] - 11s - loss: 0.4420 - acc: 0.8416 - val_loss: 0.9837 - val_acc: 0.7199\n",
      "Epoch 5/60\n",
      "103/103 [==============================] - 11s - loss: 0.4098 - acc: 0.8521 - val_loss: 1.0498 - val_acc: 0.7018\n",
      "Epoch 6/60\n",
      "103/103 [==============================] - 11s - loss: 0.3949 - acc: 0.8594 - val_loss: 0.9201 - val_acc: 0.7470\n",
      "Epoch 7/60\n",
      "103/103 [==============================] - 11s - loss: 0.4004 - acc: 0.8555 - val_loss: 0.9975 - val_acc: 0.7259\n",
      "Epoch 8/60\n",
      "103/103 [==============================] - 11s - loss: 0.3728 - acc: 0.8627 - val_loss: 1.0986 - val_acc: 0.7289\n",
      "Epoch 9/60\n",
      "103/103 [==============================] - 11s - loss: 0.3673 - acc: 0.8663 - val_loss: 0.9617 - val_acc: 0.7319\n",
      "Epoch 10/60\n",
      "103/103 [==============================] - 11s - loss: 0.3882 - acc: 0.8609 - val_loss: 0.8519 - val_acc: 0.7380\n",
      "Epoch 11/60\n",
      "103/103 [==============================] - 11s - loss: 0.3471 - acc: 0.8757 - val_loss: 0.8991 - val_acc: 0.7470\n",
      "Epoch 12/60\n",
      "103/103 [==============================] - 11s - loss: 0.3493 - acc: 0.8727 - val_loss: 0.9384 - val_acc: 0.7380\n",
      "Epoch 13/60\n",
      "103/103 [==============================] - 11s - loss: 0.3661 - acc: 0.8702 - val_loss: 0.8776 - val_acc: 0.7380\n",
      "Epoch 14/60\n",
      "103/103 [==============================] - 11s - loss: 0.3151 - acc: 0.8885 - val_loss: 0.9163 - val_acc: 0.7229\n",
      "Epoch 15/60\n",
      "103/103 [==============================] - 11s - loss: 0.3360 - acc: 0.8800 - val_loss: 0.9195 - val_acc: 0.7651\n",
      "Epoch 16/60\n",
      "103/103 [==============================] - 11s - loss: 0.3140 - acc: 0.8935 - val_loss: 0.9627 - val_acc: 0.7319\n",
      "Epoch 17/60\n",
      "103/103 [==============================] - 11s - loss: 0.3325 - acc: 0.8839 - val_loss: 0.8242 - val_acc: 0.7470\n",
      "Epoch 18/60\n",
      "103/103 [==============================] - 11s - loss: 0.3103 - acc: 0.8883 - val_loss: 0.8999 - val_acc: 0.7380\n",
      "Epoch 19/60\n",
      "103/103 [==============================] - 11s - loss: 0.3072 - acc: 0.8874 - val_loss: 0.9429 - val_acc: 0.7199\n",
      "Epoch 20/60\n",
      "103/103 [==============================] - 11s - loss: 0.3240 - acc: 0.8861 - val_loss: 1.0253 - val_acc: 0.7349\n",
      "Epoch 21/60\n",
      "103/103 [==============================] - 11s - loss: 0.3060 - acc: 0.8865 - val_loss: 0.8850 - val_acc: 0.7199\n",
      "Epoch 22/60\n",
      "103/103 [==============================] - 11s - loss: 0.2795 - acc: 0.8983 - val_loss: 0.8586 - val_acc: 0.7380\n",
      "Epoch 23/60\n",
      "103/103 [==============================] - 11s - loss: 0.2944 - acc: 0.8987 - val_loss: 0.9571 - val_acc: 0.7199\n",
      "Epoch 24/60\n",
      "103/103 [==============================] - 12s - loss: 0.2978 - acc: 0.8946 - val_loss: 0.9657 - val_acc: 0.7380\n",
      "Epoch 25/60\n",
      "103/103 [==============================] - 11s - loss: 0.2567 - acc: 0.9059 - val_loss: 0.9241 - val_acc: 0.7319\n",
      "Epoch 26/60\n",
      "103/103 [==============================] - 11s - loss: 0.2820 - acc: 0.9035 - val_loss: 0.7955 - val_acc: 0.7560\n",
      "Epoch 27/60\n",
      "103/103 [==============================] - 11s - loss: 0.2742 - acc: 0.9016 - val_loss: 0.9572 - val_acc: 0.7410\n",
      "Epoch 28/60\n",
      "103/103 [==============================] - 11s - loss: 0.2783 - acc: 0.8989 - val_loss: 0.9254 - val_acc: 0.7229\n",
      "Epoch 29/60\n",
      "103/103 [==============================] - 11s - loss: 0.2695 - acc: 0.9052 - val_loss: 0.8616 - val_acc: 0.7530\n",
      "Epoch 30/60\n",
      "103/103 [==============================] - 11s - loss: 0.2709 - acc: 0.9028 - val_loss: 1.0361 - val_acc: 0.7199\n",
      "Epoch 31/60\n",
      "103/103 [==============================] - 12s - loss: 0.2813 - acc: 0.8949 - val_loss: 0.8592 - val_acc: 0.7620\n",
      "Epoch 32/60\n",
      "103/103 [==============================] - 11s - loss: 0.2689 - acc: 0.9040 - val_loss: 0.9717 - val_acc: 0.7410\n",
      "Epoch 33/60\n",
      "103/103 [==============================] - 11s - loss: 0.2583 - acc: 0.9067 - val_loss: 0.9761 - val_acc: 0.7289\n",
      "Epoch 34/60\n",
      "103/103 [==============================] - 11s - loss: 0.2604 - acc: 0.9034 - val_loss: 0.8782 - val_acc: 0.7741\n",
      "Epoch 35/60\n",
      "103/103 [==============================] - 11s - loss: 0.2456 - acc: 0.9101 - val_loss: 0.8460 - val_acc: 0.7681\n",
      "Epoch 36/60\n",
      "103/103 [==============================] - 11s - loss: 0.2526 - acc: 0.9180 - val_loss: 1.1166 - val_acc: 0.7319\n",
      "Epoch 37/60\n",
      "103/103 [==============================] - 11s - loss: 0.2448 - acc: 0.9101 - val_loss: 0.8868 - val_acc: 0.7590\n",
      "Epoch 38/60\n",
      "103/103 [==============================] - 11s - loss: 0.2562 - acc: 0.9077 - val_loss: 1.0397 - val_acc: 0.7259\n",
      "Epoch 39/60\n",
      "103/103 [==============================] - 11s - loss: 0.2303 - acc: 0.9150 - val_loss: 0.7827 - val_acc: 0.7771\n",
      "Epoch 40/60\n",
      "103/103 [==============================] - 11s - loss: 0.2296 - acc: 0.9195 - val_loss: 0.9680 - val_acc: 0.7440\n",
      "Epoch 41/60\n",
      "103/103 [==============================] - 11s - loss: 0.2334 - acc: 0.9205 - val_loss: 0.8809 - val_acc: 0.7590\n",
      "Epoch 42/60\n",
      "103/103 [==============================] - 11s - loss: 0.2367 - acc: 0.9147 - val_loss: 0.9760 - val_acc: 0.7560\n",
      "Epoch 43/60\n",
      "103/103 [==============================] - 11s - loss: 0.2424 - acc: 0.9136 - val_loss: 0.9015 - val_acc: 0.7410\n",
      "Epoch 44/60\n",
      "103/103 [==============================] - 11s - loss: 0.2366 - acc: 0.9149 - val_loss: 0.9637 - val_acc: 0.7831\n",
      "Epoch 45/60\n",
      "103/103 [==============================] - 11s - loss: 0.2208 - acc: 0.9222 - val_loss: 0.8265 - val_acc: 0.7620\n",
      "Epoch 46/60\n",
      "103/103 [==============================] - 11s - loss: 0.2516 - acc: 0.9116 - val_loss: 0.9772 - val_acc: 0.7681\n",
      "Epoch 47/60\n",
      "103/103 [==============================] - 11s - loss: 0.2153 - acc: 0.9211 - val_loss: 0.9392 - val_acc: 0.7530\n",
      "Epoch 48/60\n",
      "103/103 [==============================] - 11s - loss: 0.2172 - acc: 0.9254 - val_loss: 1.0038 - val_acc: 0.7410\n",
      "Epoch 49/60\n",
      "103/103 [==============================] - 11s - loss: 0.2128 - acc: 0.9216 - val_loss: 0.8459 - val_acc: 0.7590\n",
      "Epoch 50/60\n",
      "103/103 [==============================] - 11s - loss: 0.2130 - acc: 0.9149 - val_loss: 0.9781 - val_acc: 0.7651\n",
      "Epoch 51/60\n",
      "103/103 [==============================] - 11s - loss: 0.2281 - acc: 0.9189 - val_loss: 0.9004 - val_acc: 0.7741\n",
      "Epoch 52/60\n",
      "103/103 [==============================] - 11s - loss: 0.2123 - acc: 0.9239 - val_loss: 1.0132 - val_acc: 0.7470\n",
      "Epoch 53/60\n",
      "103/103 [==============================] - 11s - loss: 0.2057 - acc: 0.9249 - val_loss: 0.8507 - val_acc: 0.7861\n",
      "Epoch 54/60\n",
      "103/103 [==============================] - 11s - loss: 0.2211 - acc: 0.9269 - val_loss: 0.9871 - val_acc: 0.7440\n",
      "Epoch 55/60\n",
      "103/103 [==============================] - 11s - loss: 0.2017 - acc: 0.9328 - val_loss: 1.0031 - val_acc: 0.7380\n",
      "Epoch 56/60\n",
      "103/103 [==============================] - 11s - loss: 0.1995 - acc: 0.9283 - val_loss: 0.8461 - val_acc: 0.7771\n",
      "Epoch 57/60\n",
      "103/103 [==============================] - 11s - loss: 0.2087 - acc: 0.9248 - val_loss: 0.9033 - val_acc: 0.7590\n",
      "Epoch 58/60\n",
      "103/103 [==============================] - 11s - loss: 0.2066 - acc: 0.9262 - val_loss: 0.8545 - val_acc: 0.7952\n",
      "Epoch 59/60\n",
      "103/103 [==============================] - 11s - loss: 0.2164 - acc: 0.9289 - val_loss: 1.0077 - val_acc: 0.7500\n",
      "Epoch 60/60\n",
      "103/103 [==============================] - 11s - loss: 0.1937 - acc: 0.9411 - val_loss: 1.0349 - val_acc: 0.7681\n"
     ]
    }
   ],
   "source": [
    "result = model.fit_generator(generator=train_generator,\n",
    "                             steps_per_epoch=train_generator.samples//batch_size,\n",
    "                             epochs=60,\n",
    "                             validation_data=test_generator,\n",
    "                             validation_steps=test_generator.samples//batch_size,\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.99%\n"
     ]
    }
   ],
   "source": [
    "print \"{:.2%}\".format(np.average(result.history['val_acc'][-5:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionV3 - tf suggested hyperparams\n",
    "\n",
    "* https://github.com/tensorflow/models/blob/master/slim/scripts/finetune_inception_v3_on_flowers.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"inception_v3/mixed10/concat:0\", shape=(?, 2, 2, 2048), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "base_model = applications.inception_v3.InceptionV3(weights='imagenet', include_top=False)\n",
    "# net = base_model.output\n",
    "input_tensor = Input(image_shape)\n",
    "net = base_model(input_tensor)\n",
    "print net\n",
    "net = GlobalAveragePooling2D()(net) # 2048\n",
    "# net = Dense(1024, activation='relu')(net) # more like original inceptionV3\n",
    "net = Dense(5, activation='softmax')(net)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=net)\n",
    "\n",
    "# freeze whole base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "# https://github.com/tensorflow/models/blob/master/slim/scripts/finetune_inception_v3_on_flowers.sh\n",
    "# step=1000 => epoch=10\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.01, decay=0.00004), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "103/103 [==============================] - 11s - loss: 3.7714 - acc: 0.4078 - val_loss: 4.1936 - val_acc: 0.4970\n",
      "Epoch 2/20\n",
      "103/103 [==============================] - 11s - loss: 2.2959 - acc: 0.5367 - val_loss: 3.2972 - val_acc: 0.4849\n",
      "Epoch 3/20\n",
      "103/103 [==============================] - 11s - loss: 2.1293 - acc: 0.5840 - val_loss: 1.9660 - val_acc: 0.6235\n",
      "Epoch 4/20\n",
      "103/103 [==============================] - 11s - loss: 2.0594 - acc: 0.6014 - val_loss: 2.1774 - val_acc: 0.5994\n",
      "Epoch 5/20\n",
      "103/103 [==============================] - 11s - loss: 2.2425 - acc: 0.5854 - val_loss: 2.8260 - val_acc: 0.5572\n",
      "Epoch 6/20\n",
      "103/103 [==============================] - 11s - loss: 2.1303 - acc: 0.6069 - val_loss: 3.9913 - val_acc: 0.4488\n",
      "Epoch 7/20\n",
      "103/103 [==============================] - 11s - loss: 2.0821 - acc: 0.6075 - val_loss: 3.0431 - val_acc: 0.5994\n",
      "Epoch 8/20\n",
      "103/103 [==============================] - 11s - loss: 2.1690 - acc: 0.6081 - val_loss: 3.5379 - val_acc: 0.5181\n",
      "Epoch 9/20\n",
      "103/103 [==============================] - 11s - loss: 2.0560 - acc: 0.6268 - val_loss: 2.4091 - val_acc: 0.59340.6\n",
      "Epoch 10/20\n",
      "103/103 [==============================] - 11s - loss: 2.0666 - acc: 0.6239 - val_loss: 3.8185 - val_acc: 0.5392\n",
      "Epoch 11/20\n",
      "103/103 [==============================] - 11s - loss: 2.1970 - acc: 0.6107 - val_loss: 2.5074 - val_acc: 0.5843\n",
      "Epoch 12/20\n",
      "103/103 [==============================] - 11s - loss: 2.0003 - acc: 0.6472 - val_loss: 2.3098 - val_acc: 0.5783\n",
      "Epoch 13/20\n",
      "103/103 [==============================] - 11s - loss: 1.9914 - acc: 0.6360 - val_loss: 2.6396 - val_acc: 0.5783\n",
      "Epoch 14/20\n",
      "103/103 [==============================] - 11s - loss: 2.0497 - acc: 0.6281 - val_loss: 2.3084 - val_acc: 0.5964\n",
      "Epoch 15/20\n",
      "103/103 [==============================] - 11s - loss: 2.0229 - acc: 0.6300 - val_loss: 1.9583 - val_acc: 0.6476\n",
      "Epoch 16/20\n",
      "103/103 [==============================] - 11s - loss: 2.0116 - acc: 0.6368 - val_loss: 3.2301 - val_acc: 0.5452\n",
      "Epoch 17/20\n",
      "103/103 [==============================] - 11s - loss: 1.9001 - acc: 0.6480 - val_loss: 2.3467 - val_acc: 0.5783\n",
      "Epoch 18/20\n",
      "103/103 [==============================] - 11s - loss: 1.8680 - acc: 0.6575 - val_loss: 2.9074 - val_acc: 0.5873\n",
      "Epoch 19/20\n",
      "103/103 [==============================] - 11s - loss: 2.0371 - acc: 0.6325 - val_loss: 2.4563 - val_acc: 0.6566\n",
      "Epoch 20/20\n",
      "103/103 [==============================] - 11s - loss: 2.0481 - acc: 0.6366 - val_loss: 2.5799 - val_acc: 0.5633\n"
     ]
    }
   ],
   "source": [
    "result = model.fit_generator(generator=train_generator,\n",
    "                             steps_per_epoch=train_generator.samples//batch_size,\n",
    "                             epochs=20,\n",
    "                             validation_data=test_generator,\n",
    "                             validation_steps=test_generator.samples//batch_size,\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trainable=True for whole model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.compile(optimizer=optimizers.SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# https://github.com/tensorflow/models/blob/master/slim/scripts/finetune_inception_v3_on_flowers.sh\n",
    "# step=500 => epoch=5\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.0001, decay=0.00004), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "103/103 [==============================] - 12s - loss: 0.0541 - acc: 0.9827 - val_loss: 0.8537 - val_acc: 0.8675\n",
      "Epoch 2/10\n",
      "103/103 [==============================] - 12s - loss: 0.0540 - acc: 0.9812 - val_loss: 0.6671 - val_acc: 0.8795\n",
      "Epoch 3/10\n",
      "103/103 [==============================] - 12s - loss: 0.0616 - acc: 0.9817 - val_loss: 1.1726 - val_acc: 0.8434\n",
      "Epoch 4/10\n",
      "103/103 [==============================] - 12s - loss: 0.0606 - acc: 0.9823 - val_loss: 1.0827 - val_acc: 0.8645\n",
      "Epoch 5/10\n",
      "103/103 [==============================] - 12s - loss: 0.0664 - acc: 0.9815 - val_loss: 1.0400 - val_acc: 0.8494\n",
      "Epoch 6/10\n",
      "103/103 [==============================] - 12s - loss: 0.0568 - acc: 0.9845 - val_loss: 1.4945 - val_acc: 0.8253\n",
      "Epoch 7/10\n",
      "103/103 [==============================] - 12s - loss: 0.0537 - acc: 0.9857 - val_loss: 0.7556 - val_acc: 0.8886\n",
      "Epoch 8/10\n",
      "103/103 [==============================] - 12s - loss: 0.0469 - acc: 0.9860 - val_loss: 1.0312 - val_acc: 0.8705\n",
      "Epoch 9/10\n",
      "103/103 [==============================] - 12s - loss: 0.0465 - acc: 0.9879 - val_loss: 1.1135 - val_acc: 0.8795\n",
      "Epoch 10/10\n",
      "103/103 [==============================] - 12s - loss: 0.0559 - acc: 0.9875 - val_loss: 1.3776 - val_acc: 0.8283\n"
     ]
    }
   ],
   "source": [
    "result = model.fit_generator(generator=train_generator,\n",
    "                             steps_per_epoch=train_generator.samples//batch_size,\n",
    "                             epochs=10,\n",
    "                             validation_data=test_generator,\n",
    "                             validation_steps=test_generator.samples//batch_size,\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.84%\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "print \"{:.2%}\".format(np.average(result.history['val_acc'][-5:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.75%\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "print \"{:.2%}\".format(np.average(result.history['val_acc'][-5:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.54%\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "print \"{:.2%}\".format(np.average(result.history['val_acc'][-5:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check `top` of InceptionV3\n",
    "\n",
    "* tf-slim 코드를 보니 auxLogit 이라는 게 있음 (auxiliary logit)\n",
    "* 아마 이게 inceptionV3 에 auxiliary classifier 부분아닐까 싶음\n",
    "* 이부분이 케라스에도 동일하게 있는지 체크해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
      "96043008/96112376 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "comp_model = applications.inception_v3.InceptionV3(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comp_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.normalization.BatchNormalization at 0x7efcea946d10>,\n",
       " <keras.layers.core.Activation at 0x7efceadb0f10>,\n",
       " <keras.layers.merge.Concatenate at 0x7efceabea910>,\n",
       " <keras.layers.merge.Concatenate at 0x7efcea9c9710>,\n",
       " <keras.layers.core.Activation at 0x7efcea973750>,\n",
       " <keras.layers.merge.Concatenate at 0x7efcea90af50>,\n",
       " <keras.layers.pooling.GlobalAveragePooling2D at 0x7efceb28ce10>,\n",
       " <keras.layers.core.Dense at 0x7efcea8c4f50>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_model.layers[-8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Activation at 0x7efcf539af50>,\n",
       " <keras.layers.core.Activation at 0x7efcf536bd50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7efcf52fd410>,\n",
       " <keras.layers.core.Activation at 0x7efcf56d3f10>,\n",
       " <keras.layers.merge.Concatenate at 0x7efcf550dc50>,\n",
       " <keras.layers.merge.Concatenate at 0x7efcf532eb10>,\n",
       " <keras.layers.core.Activation at 0x7efcf5294e50>,\n",
       " <keras.layers.merge.Concatenate at 0x7efcf5252090>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.layers[-8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 - tf.latest",
   "language": "python",
   "name": "python2-tf-latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
