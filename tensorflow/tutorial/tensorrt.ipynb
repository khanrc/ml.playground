{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.8.0', '4.0.1.6', '0.3.0')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorrt as trt\n",
    "from tensorrt.parsers import uffparser\n",
    "import uff\n",
    "\n",
    "tf.__version__, trt.__version__, uff.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import numpy as np\n",
    "from random import randint # generate a random test case\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow # To show test case\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load frozen graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = '/home/trt/inferences/handol'\n",
    "pb_path = '/home/trt/inferences/hd-nod.pb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pb_path, 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_def = tf.graph_util.remove_training_nodes(graph_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.import_graph_def(graph_def, name=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(396, 396)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph_def.node), len(tf.get_default_graph().as_graph_def().node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = graph.get_tensor_by_name('state:0') # 굳이 필요없음\n",
    "logits = graph.get_tensor_by_name(\"tower0/policy_head/logits/BiasAdd:0\")\n",
    "probs = graph.get_tensor_by_name(\"tower0/policy_head/softmax:0\")\n",
    "value = graph.get_tensor_by_name(\"tower0/value_head/value/Tanh:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = np.random.randint(0, 2, size=(1, 18, 19, 19)).astype(np.float32)\n",
    "s = np.ones([1, 18, 19, 19]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg, p, v = sess.run([logits, probs, value], {'state:0': s})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.4598145]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write this graph to pb file\n",
    "# tf.train.write_graph(graph_def, os.path.dirname(pb_path), 'hd_rm_trn.pb', as_text=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the TensorFlow Model to UFF\n",
    "\n",
    "- 일단 이 frozen graph 를 serialized UFF model 로 컨버팅해야 한다.\n",
    "- `uff.from_tensorflow()` 를 사용할것이며 output node name 만 알면 댐.\n",
    "    - `quiet` mode to suppress conversion logging\n",
    "    - `input_nodes` to allow you to define a set of input nodes in the graph (the defaults are Placeholder nodes)\n",
    "    - `output_nodes`\n",
    "    - `text` will let you save a human readable version of UFF model alongside the binary UFF\n",
    "    - `list_nodes` will list the nodes in the graph\n",
    "    - `output_filename` will write the model out to the filepath specified in addition to returning a serialized model\n",
    "- `uff.from_tensorflow_frozen_model()` 은 pb 파일로부터 직접 읽어서 변경하는 함수인듯."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using output node tower0/policy_head/softmax\n",
      "Using output node tower0/value_head/value/Tanh\n",
      "Converting to UFF graph\n",
      "DEBUG: convert reshape to flatten node\n",
      "DEBUG: convert reshape to flatten node\n",
      "No. nodes: 384\n"
     ]
    }
   ],
   "source": [
    "# [!] 주의: 여기서는 tensor:0 에서 :0 을 지워줘야 함! (즉 텐서를 가리키는게 아니라 오퍼레이션을 가리켜야 함)\n",
    "input_node_names = [\n",
    "    \"state\" # state\n",
    "]\n",
    "output_node_names = [\n",
    "    \"tower0/policy_head/softmax\", # probs\n",
    "    \"tower0/value_head/value/Tanh\" # values\n",
    "]\n",
    "uff_model = uff.from_tensorflow(graph_def, output_nodes=output_node_names, input_nodes=input_node_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the UFF Model into TensorRT and Building an Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 우리는 이제 UFF model stream 을 가지고 있다 (왜 스트림이지). 이걸로 TRT Engine 을 만들어보자.\n",
    "# 먼저 로거를 세팅\n",
    "G_LOGGER = trt.infer.ConsoleLogger(trt.infer.LogSeverity.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UFF parser 를 세팅하고 input/output nodes 세팅\n",
    "parser = uffparser.create_uff_parser()\n",
    "parser.register_input(\"state\", (18, 19, 19), 0)\n",
    "for op_node_name in output_node_names:\n",
    "    parser.register_output(op_node_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 << 30 == 2 ** 30 == 1 GB (GPU memory)\n",
    "# TensorRT 엔진 빌드\n",
    "engine = trt.utils.uff_to_trt_engine(G_LOGGER, uff_model, parser, \n",
    "                                     max_batch_size=1,\n",
    "                                     max_workspace_size=2<<30,\n",
    "                                     datatype=trt.infer.DataType.FLOAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for binding 0,\n",
      "name  : state\n",
      "dtype : DataType.FLOAT\n",
      "dim   : 18 19 19\n",
      "\n",
      "for binding 1,\n",
      "name  : tower0/policy_head/softmax\n",
      "dtype : DataType.FLOAT\n",
      "dim   : 1 1 362\n",
      "\n",
      "for binding 2,\n",
      "name  : tower0/value_head/value/Tanh\n",
      "dtype : DataType.FLOAT\n",
      "dim   : 1 1 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(engine.get_nb_bindings()):\n",
    "    print(\"for binding {},\".format(i))\n",
    "    print(\"name  :\", engine.get_binding_name(i))\n",
    "    # data types: trt.infer.DataType\n",
    "    dtype = engine.get_binding_data_type(i)\n",
    "    print(\"dtype :\", trt.infer.DataType(dtype))\n",
    "    dims = engine.get_binding_dimensions(i).to_DimsCHW()\n",
    "    print(\"dim   :\", dims.C(), dims.H(), dims.W())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorRT Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runtime 및 engine 의 execution context 생성\n",
    "runtime = trt.infer.create_infer_runtime(G_LOGGER)\n",
    "context = engine.create_execution_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 362), (1, 1))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU memory allocation for input/output\n",
    "trt_probs = np.zeros(362, dtype=np.float32)\n",
    "trt_value = np.zeros(1, dtype=np.float32)\n",
    "\n",
    "# allocation\n",
    "B = 1 # batch size\n",
    "d_input = cuda.mem_alloc(B * s.nbytes)\n",
    "d_probs = cuda.mem_alloc(B * trt_probs.nbytes)\n",
    "d_value = cuda.mem_alloc(B * trt_value.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRT engine 은 GPU memory pointer binding 을 해줘야 함\n",
    "bindings = [int(d_input), int(d_probs), int(d_value)] # int 는 pointer 주소 타입캐스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = cuda.Stream()\n",
    "# input data 를 GPU 로 이동 (미리 지정해둔 d_input 으로). 아마 htod 는 host to device 일듯?\n",
    "cuda.memcpy_htod_async(d_input, s, stream)\n",
    "# 모델 실행\n",
    "context.enqueue(B, bindings, stream.handle, None)\n",
    "# 결과를 다시 CPU 로 가져옴\n",
    "cuda.memcpy_dtoh_async(trt_probs, d_probs, stream)\n",
    "cuda.memcpy_dtoh_async(trt_value, d_value, stream)\n",
    "# synchronize\n",
    "stream.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.45982668], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trt_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.51043246e-03, 6.33322692e-04, 2.56291678e-04, 2.19770081e-04,\n",
       "       2.00626411e-04, 1.83451484e-04, 1.53308400e-04, 1.36889910e-04,\n",
       "       1.20051969e-04, 1.10205699e-04, 9.74680297e-05, 8.83465254e-05,\n",
       "       8.56449333e-05, 8.11104619e-05, 7.72784260e-05, 8.17085456e-05,\n",
       "       7.99662375e-05, 1.78305665e-04, 2.15001302e-04, 8.68667208e-04,\n",
       "       1.77537018e-04, 9.63208731e-05, 7.90810154e-05, 7.12442561e-05,\n",
       "       6.35947363e-05, 5.69060030e-05, 5.53523168e-05, 4.76644673e-05,\n",
       "       4.34321992e-05, 3.99638302e-05, 3.55924312e-05, 3.25350120e-05,\n",
       "       3.15799443e-05, 3.04895530e-05, 3.15419602e-05, 3.17104386e-05,\n",
       "       4.26606821e-05, 1.64073586e-04, 1.36321061e-03, 2.67722644e-04,\n",
       "       9.27539368e-05, 6.57643541e-05, 5.94052144e-05, 4.49812069e-05,\n",
       "       4.53172688e-05, 3.62654682e-05, 3.39658072e-05, 2.78475491e-05,\n",
       "       2.51144866e-05, 2.11071747e-05, 2.03853051e-05, 1.57005761e-05,\n",
       "       1.82831864e-05, 1.68487077e-05, 1.75055557e-05, 3.02435710e-05,\n",
       "       9.13490585e-05, 4.69793240e-03, 4.27350402e-04, 2.48921715e-04,\n",
       "       1.40391770e-04, 1.06899053e-04, 5.60270164e-05, 4.91637184e-05,\n",
       "       4.11361543e-05, 3.40437327e-05, 2.90667103e-05, 2.65834442e-05,\n",
       "       2.45082956e-05, 2.38110952e-05, 2.22660583e-05, 2.13060139e-05,\n",
       "       1.55939560e-05, 1.85055160e-05, 3.13660275e-05, 8.55968756e-05,\n",
       "       4.05481411e-03, 1.15022820e-03, 3.47440859e-04, 1.92693667e-04,\n",
       "       2.11552280e-04, 1.36985371e-04, 7.36332004e-05, 4.58549548e-05,\n",
       "       3.76243770e-05, 3.03925899e-05, 2.80530603e-05, 2.63115762e-05,\n",
       "       2.51208585e-05, 2.27003038e-05, 2.28535719e-05, 2.07458779e-05,\n",
       "       2.24339747e-05, 3.20606778e-05, 9.31515533e-05, 8.54112487e-03,\n",
       "       1.64659764e-03, 5.64238871e-04, 4.54743189e-04, 4.03420680e-04,\n",
       "       4.14383365e-04, 1.69051942e-04, 7.67564270e-05, 3.73183757e-05,\n",
       "       3.21429106e-05, 3.01710043e-05, 2.73112746e-05, 2.39996552e-05,\n",
       "       2.16604294e-05, 2.01807707e-05, 1.89293351e-05, 1.65583642e-05,\n",
       "       3.20154904e-05, 8.81536689e-05, 1.26401316e-02, 2.12398404e-03,\n",
       "       3.86188668e-03, 8.70297896e-04, 8.45005852e-04, 5.53958060e-04,\n",
       "       1.73864129e-04, 6.26093242e-05, 5.14619460e-05, 4.74198605e-05,\n",
       "       3.69640620e-05, 3.46149172e-05, 2.86035229e-05, 2.35230509e-05,\n",
       "       2.07974426e-05, 1.96435649e-05, 2.06232980e-05, 7.18440642e-05,\n",
       "       1.05375009e-04, 2.78370641e-02, 2.98946723e-03, 4.74128313e-03,\n",
       "       1.22815685e-03, 4.96239634e-04, 2.14947780e-04, 5.51075536e-05,\n",
       "       4.26700026e-05, 4.51480009e-05, 5.65022092e-05, 5.38320674e-05,\n",
       "       6.38413840e-05, 3.04852492e-05, 2.57693173e-05, 2.38185676e-05,\n",
       "       2.08466881e-05, 2.22313247e-05, 7.97526154e-05, 1.71939537e-04,\n",
       "       6.34511933e-02, 3.33454343e-03, 5.79601806e-03, 1.18045602e-03,\n",
       "       2.58367654e-04, 9.38952726e-05, 4.67035643e-05, 4.00476929e-05,\n",
       "       3.84203122e-05, 3.83106562e-05, 1.13287504e-04, 1.92250824e-04,\n",
       "       3.84889245e-05, 2.86576669e-05, 2.56350686e-05, 2.22642557e-05,\n",
       "       2.60162742e-05, 1.86300342e-04, 2.15251901e-04, 1.08908951e-01,\n",
       "       2.22618366e-03, 3.09948693e-03, 6.99060271e-04, 1.54368230e-04,\n",
       "       5.84161098e-05, 4.41591728e-05, 3.54683143e-05, 3.50660921e-05,\n",
       "       3.44514701e-05, 3.73755356e-05, 6.52886156e-05, 5.01030299e-05,\n",
       "       2.87094499e-05, 2.51163056e-05, 2.24046616e-05, 2.55122213e-05,\n",
       "       1.94659908e-04, 2.17088105e-04, 2.05476016e-01, 1.50735292e-03,\n",
       "       1.68254040e-02, 1.59825385e-03, 1.88811347e-04, 5.63231661e-05,\n",
       "       4.51358610e-05, 3.42919629e-05, 3.25502879e-05, 3.22119849e-05,\n",
       "       3.73815965e-05, 4.75100314e-05, 5.93933801e-05, 3.00910342e-05,\n",
       "       2.51218426e-05, 2.33094961e-05, 2.83556874e-05, 2.71939411e-04,\n",
       "       1.51095752e-04, 1.18321389e-01, 1.97297800e-03, 1.30245490e-02,\n",
       "       1.02250604e-03, 1.03349237e-04, 6.96187126e-05, 4.00943936e-05,\n",
       "       3.36851299e-05, 2.91702654e-05, 2.76303363e-05, 3.35084587e-05,\n",
       "       4.38729767e-05, 4.41744633e-05, 3.23445711e-05, 2.43559152e-05,\n",
       "       2.16520457e-05, 2.57863030e-05, 2.05118107e-04, 1.02154576e-04,\n",
       "       8.29542503e-02, 1.74765813e-03, 6.58984017e-03, 1.05366029e-03,\n",
       "       7.16475479e-05, 4.67003156e-05, 3.89914494e-05, 3.42256099e-05,\n",
       "       3.09492025e-05, 2.90468433e-05, 3.26674635e-05, 3.22884771e-05,\n",
       "       8.04641750e-05, 7.22825862e-05, 2.86730592e-05, 2.27946257e-05,\n",
       "       2.21011705e-05, 9.24451597e-05, 9.31624381e-05, 1.49596874e-02,\n",
       "       3.57912679e-04, 5.74004720e-04, 1.13997282e-03, 5.69359727e-05,\n",
       "       4.30611763e-05, 3.81199025e-05, 3.13919445e-05, 2.65852705e-05,\n",
       "       2.29579236e-05, 2.25840013e-05, 2.30778460e-05, 2.44725634e-05,\n",
       "       4.81618372e-05, 2.41931921e-05, 1.97433292e-05, 1.50056303e-05,\n",
       "       3.70287344e-05, 8.16066895e-05, 3.82311107e-03, 1.03696468e-04,\n",
       "       1.65768914e-04, 5.69486219e-05, 4.72074280e-05, 4.01245743e-05,\n",
       "       3.61257007e-05, 3.05998983e-05, 2.67587202e-05, 2.44149833e-05,\n",
       "       2.32581369e-05, 2.35398365e-05, 2.51476577e-05, 2.48999932e-05,\n",
       "       2.63350212e-05, 2.01959992e-05, 1.97793233e-05, 2.84765792e-05,\n",
       "       7.93328945e-05, 3.72294540e-04, 8.17862019e-05, 4.43364479e-05,\n",
       "       2.77546224e-05, 3.86231332e-05, 3.70394373e-05, 3.41006635e-05,\n",
       "       3.00253323e-05, 2.49234890e-05, 2.27665787e-05, 2.15806140e-05,\n",
       "       2.09901427e-05, 2.23480274e-05, 2.14683096e-05, 1.97472073e-05,\n",
       "       1.47995434e-05, 1.70617586e-05, 2.55418745e-05, 6.92239264e-05,\n",
       "       2.20499613e-04, 8.71049633e-05, 3.60691774e-05, 2.93291505e-05,\n",
       "       3.36573212e-05, 2.58512846e-05, 2.69782122e-05, 2.48075776e-05,\n",
       "       2.38415214e-05, 2.14079955e-05, 2.12256837e-05, 2.11713632e-05,\n",
       "       1.94540007e-05, 1.51334207e-05, 1.87533715e-05, 1.69647501e-05,\n",
       "       1.49344896e-05, 2.66216757e-05, 6.97536889e-05, 1.91580315e-04,\n",
       "       1.27790030e-04, 5.71540695e-05, 4.99879607e-05, 6.45920736e-05,\n",
       "       4.50240841e-05, 7.93457511e-05, 4.51697451e-05, 3.90418318e-05,\n",
       "       3.67422253e-05, 3.50446971e-05, 3.39471517e-05, 3.12913944e-05,\n",
       "       3.17289487e-05, 2.82023684e-05, 2.69331722e-05, 2.69950706e-05,\n",
       "       3.84048872e-05, 9.61560436e-05, 3.48545844e-04, 1.96638648e-04,\n",
       "       1.41134078e-04, 1.38611664e-04, 1.24462342e-04, 1.18336800e-04,\n",
       "       1.06113388e-04, 9.92231726e-05, 9.16042700e-05, 8.42322988e-05,\n",
       "       8.15496969e-05, 7.95744199e-05, 8.03948351e-05, 7.58361421e-05,\n",
       "       7.63530625e-05, 7.54776993e-05, 7.91797647e-05, 1.07116975e-04,\n",
       "       2.11011749e-04, 2.33028546e-01], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trt_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.218915e-05"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.abs(trt_value - v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.142523e-06"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.abs(p - trt_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save TRT engine to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is PLAN file!\n",
    "# trt.utils.write_engine_to_file('./trt_hd.engine', engine.serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also you can load like this:\n",
    "# new_engine = trt.utils.load_engine(G_LOGGER, \"./trt_hd.engine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.destroy()\n",
    "engine.destroy()\n",
    "runtime.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runtime comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_run(s):\n",
    "    p, v = sess.run([probs, value], {'state:0': s})\n",
    "    return p, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger\n",
    "G_LOGGER = trt.infer.ConsoleLogger(trt.infer.LogSeverity.ERROR)\n",
    "\n",
    "# parser\n",
    "parser = uffparser.create_uff_parser()\n",
    "parser.register_input(\"state\", (18, 19, 19), 0)\n",
    "for op_node_name in output_node_names:\n",
    "    parser.register_output(op_node_name)\n",
    "\n",
    "# engine\n",
    "engine = trt.utils.uff_to_trt_engine(G_LOGGER, uff_model, parser, \n",
    "                                     max_batch_size=1,\n",
    "                                     max_workspace_size=2<<30)\n",
    "\n",
    "# runtime & context\n",
    "runtime = trt.infer.create_infer_runtime(G_LOGGER)\n",
    "context = engine.create_execution_context()\n",
    "\n",
    "# GPU memory allocation for input/output\n",
    "trt_probs = np.zeros(362, dtype=np.float32)\n",
    "trt_value = np.zeros(1, dtype=np.float32)\n",
    "\n",
    "# allocation\n",
    "B = 1 # batch size\n",
    "d_input = cuda.mem_alloc(B * s.nbytes)\n",
    "d_probs = cuda.mem_alloc(B * trt_probs.nbytes)\n",
    "d_value = cuda.mem_alloc(B * trt_value.nbytes)\n",
    "\n",
    "# TRT engine 은 GPU memory pointer binding 을 해줘야 함\n",
    "bindings = [int(d_input), int(d_probs), int(d_value)] # int 는 pointer 주소 타입캐스팅\n",
    "\n",
    "stream = cuda.Stream()\n",
    "\n",
    "def trt_run(s):    \n",
    "    cuda.memcpy_htod_async(d_input, s, stream)\n",
    "    context.enqueue(B, bindings, stream.handle, None)\n",
    "    cuda.memcpy_dtoh_async(trt_probs, d_probs, stream)\n",
    "    cuda.memcpy_dtoh_async(trt_value, d_value, stream)\n",
    "    stream.synchronize()\n",
    "    \n",
    "    return trt_probs, trt_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed: 7.66s\n",
      "208.83917188374068 n/s\n"
     ]
    }
   ],
   "source": [
    "s = np.ones((1, 18, 19, 19), dtype=np.float32)\n",
    "# warmup\n",
    "for i in range(10):\n",
    "    tf_run(s)\n",
    "# run\n",
    "st = time.time()\n",
    "for i in range(N):\n",
    "    # s = np.random.randint(0, 2, size=(1, 18, 19, 19)).astype(np.float32)\n",
    "    p, v = tf_run(s)\n",
    "\n",
    "elapsed = time.time() - st\n",
    "print(\"elapsed: {:.2f}s\".format(elapsed))\n",
    "print(\"{} n/s\".format(N / elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed: 3.42s\n",
      "468.2764970064268 n/s\n"
     ]
    }
   ],
   "source": [
    "s = np.ones((1, 18, 19, 19), dtype=np.float32)\n",
    "# warmup\n",
    "for i in range(10):\n",
    "    trt_run(s)\n",
    "# run\n",
    "st = time.time()\n",
    "for i in range(N):\n",
    "    # s = np.random.randint(0, 2, size=(1, 18, 19, 19)).astype(np.float32)\n",
    "    p, v = trt_run(s)\n",
    "\n",
    "elapsed = time.time() - st\n",
    "print(\"elapsed: {:.2f}s\".format(elapsed))\n",
    "print(\"{} n/s\".format(N / elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.destroy()\n",
    "context.destroy()\n",
    "engine.destroy()\n",
    "runtime.destroy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
