{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution\n",
    "\n",
    "Conv 는 기본적으로 matrix multiplication 연산이 아니라서 구현이 다소 tricky 한 면이 있음.\n",
    "\n",
    "1. Navie method: `for i, j in each spatial positions`\n",
    "2. img2col (unfold)\n",
    "3. weight expanding\n",
    "\n",
    "Conv 를 보기 전에 구현을 위한 조각인 unfold 를 먼저 보고 가자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing methods\n",
    "def diff(a, b):\n",
    "    return (a-b).abs().max()\n",
    "\n",
    "def compare(a, b):\n",
    "    dif = diff(a, b)\n",
    "    allclose = torch.allclose(a, b)\n",
    "    print(\"Allclose = {}, max diff = {}\".format(allclose, dif))\n",
    "    \n",
    "    if not allclose:\n",
    "        print(\"!!! Not close !!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unfold\n",
    "\n",
    "img2col 이라고 더 많이 불리는데, conv 연산을 matrix multiplication 으로 계산할 수 있도록 input x 를 잘 펼쳐준다.\n",
    "conv 연산 자체가 input x 에 대해 겹치는 연산이 있으므로 (e.g. stride=1, K=3 경우) unfold 할 때도 중복 데이터가 존재하게 unfolding 이 된다.\n",
    "\n",
    "## Methods\n",
    "\n",
    "img2col 연산이 여러가지가 존재. `Tensor.unfold` 와 `F.unfold` 를 헷갈리지 말자.\n",
    "\n",
    "- `Tensor.unfold`: 1d unfold.\n",
    "- `F.unfold`: 2d unfold. img2col 자체가 원래 2d 에 대한 얘기니까 이게 img2col 임.\n",
    "- `Tensor.as_strided`: 1d, 2d unfold 를 둘다 요걸로 구현할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d unfold\n",
    "\n",
    "특이하게 `torch.unfold` 는 없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 1\n",
    "K = 2\n",
    "C = 3\n",
    "T = 5\n",
    "stride = 1\n",
    "padding = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1221, 0.1485, 0.8846, 0.2949, 0.6597],\n",
       "         [0.8651, 0.3928, 0.7882, 0.6540, 0.7690],\n",
       "         [0.1089, 0.0725, 0.2225, 0.2966, 0.4136]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(B, C, T)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 4, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1221, 0.1485],\n",
       "          [0.8651, 0.3928],\n",
       "          [0.1089, 0.0725]],\n",
       "\n",
       "         [[0.1485, 0.8846],\n",
       "          [0.3928, 0.7882],\n",
       "          [0.0725, 0.2225]],\n",
       "\n",
       "         [[0.8846, 0.2949],\n",
       "          [0.7882, 0.6540],\n",
       "          [0.2225, 0.2966]],\n",
       "\n",
       "         [[0.2949, 0.6597],\n",
       "          [0.6540, 0.7690],\n",
       "          [0.2966, 0.4136]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# args: unfold last dim, kernel size 2, stride 1. no padding.\n",
    "unf = x.unfold(-1, K, stride)\n",
    "print(unf.shape)  # [B, C, T', K]; K=kernel, T'=T-(K-1). padding=0, stride=1 이므로 T 가 K-1 만큼 줄어듬.\n",
    "\n",
    "# for visualize, swap channel dim (1) and time dim (2).\n",
    "unf.transpose(1, 2)  # [B, T', C, K]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d unfold by as_strided\n",
    "\n",
    "어떤 view 를 리턴하는 대부분의 pytorch 함수는 내부적으로 이걸로 구현되어 있음. 그만큼 강력하고 대신 약간 쓰기 까다로운 함수.\n",
    "\n",
    "```\n",
    "torch.as_strided(input, size, stride, storage_offset=0) → Tensor\n",
    "```\n",
    "\n",
    "- torch.as_strided(input, ...) 는 input.as_strided(...) 로 쓸 수 있다.\n",
    "- size 는 output size.\n",
    "- stride 는 the stride of the output tensor 라고 되어 있는데, 이 부분이 약간 트리키함.\n",
    "  - output tensor 에서, 해당 디멘션의 index 가 바뀔 때 input tensor index 의 stride.\n",
    "  - 즉, 아래 예제에서 `stride = (C*T, T, 1, 1)` 이므로, output tensor 의 첫번째 index (batch index) 가 바뀌면 input tensor 에서 `C*T` 만큼 움직인다. input tensor 가 `[B, C, T]` 이므로 자연스럽게 다음 배치로 넘어간다.\n",
    "  - input tensor 가 flatten 되어 있다고 생각하는 것이 편하다.\n",
    "- storage_offset 은 시작 offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1221, 0.1485],\n",
       "          [0.1485, 0.8846],\n",
       "          [0.8846, 0.2949],\n",
       "          [0.2949, 0.6597]],\n",
       "\n",
       "         [[0.8651, 0.3928],\n",
       "          [0.3928, 0.7882],\n",
       "          [0.7882, 0.6540],\n",
       "          [0.6540, 0.7690]],\n",
       "\n",
       "         [[0.1089, 0.0725],\n",
       "          [0.0725, 0.2225],\n",
       "          [0.2225, 0.2966],\n",
       "          [0.2966, 0.4136]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tp = T-(K-1)\n",
    "unf_by_as = x.as_strided((B, C, Tp, K), (C*T, T, 1, 1))\n",
    "unf_by_as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allclose = True, max diff = 0.0\n"
     ]
    }
   ],
   "source": [
    "compare(unf, unf_by_as)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d unfold\n",
    "\n",
    "`[B, C, H, W]` tensor -> `[B, C*K*K, L]` tensor; `L = H_out * W_out`.\n",
    "\n",
    "- matmul 로 conv 연산이 가능하도록 `C*K*K` 로 묶어준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 1\n",
    "K = 2\n",
    "C = 4\n",
    "size = 3  # H, W\n",
    "stride = 1\n",
    "padding = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.3915, 0.0511, 0.7724],\n",
       "          [0.0454, 0.9542, 0.4523],\n",
       "          [0.7951, 0.5156, 0.0931]],\n",
       "\n",
       "         [[0.3165, 0.5458, 0.0030],\n",
       "          [0.9388, 0.8726, 0.5483],\n",
       "          [0.0543, 0.2777, 0.2357]],\n",
       "\n",
       "         [[0.5484, 0.5781, 0.1654],\n",
       "          [0.7392, 0.6313, 0.4918],\n",
       "          [0.9587, 0.9745, 0.0871]],\n",
       "\n",
       "         [[0.8928, 0.4683, 0.2547],\n",
       "          [0.9354, 0.9179, 0.2860],\n",
       "          [0.4460, 0.9646, 0.0382]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(B, C, size, size)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3915, 0.0511, 0.0454, 0.9542],\n",
       "         [0.0511, 0.7724, 0.9542, 0.4523],\n",
       "         [0.0454, 0.9542, 0.7951, 0.5156],\n",
       "         [0.9542, 0.4523, 0.5156, 0.0931],\n",
       "         [0.3165, 0.5458, 0.9388, 0.8726],\n",
       "         [0.5458, 0.0030, 0.8726, 0.5483],\n",
       "         [0.9388, 0.8726, 0.0543, 0.2777],\n",
       "         [0.8726, 0.5483, 0.2777, 0.2357],\n",
       "         [0.5484, 0.5781, 0.7392, 0.6313],\n",
       "         [0.5781, 0.1654, 0.6313, 0.4918],\n",
       "         [0.7392, 0.6313, 0.9587, 0.9745],\n",
       "         [0.6313, 0.4918, 0.9745, 0.0871],\n",
       "         [0.8928, 0.4683, 0.9354, 0.9179],\n",
       "         [0.4683, 0.2547, 0.9179, 0.2860],\n",
       "         [0.9354, 0.9179, 0.4460, 0.9646],\n",
       "         [0.9179, 0.2860, 0.9646, 0.0382]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unf = F.unfold(x, K, padding=padding, stride=stride)\n",
    "print(unf.shape)  # [B, C*K*K, L]; L = H_out * W_out\n",
    "# stride=1, padding=0, H=W=size 세팅이므로 L = (size - K + 1) ** 2\n",
    "unf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d unfold by as_strided\n",
    "\n",
    "* 1d 와 달리 한방에 unfold 와 똑같이 갈 수는 없음.\n",
    "* `[B, C, H, W]` -> `[B, C, H', W', K, K]` 로 바꾼 다음 `C*K*K` 와 `H'*W'` 을 모으자.\n",
    "* 사실 conv 를 구현한다고 하면 꼭 unfold shape 으로 맞춰줄 필욘 없을 듯."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3915, 0.0511, 0.0454, 0.9542],\n",
       "         [0.0511, 0.7724, 0.9542, 0.4523],\n",
       "         [0.0454, 0.9542, 0.7951, 0.5156],\n",
       "         [0.9542, 0.4523, 0.5156, 0.0931],\n",
       "         [0.3165, 0.5458, 0.9388, 0.8726],\n",
       "         [0.5458, 0.0030, 0.8726, 0.5483],\n",
       "         [0.9388, 0.8726, 0.0543, 0.2777],\n",
       "         [0.8726, 0.5483, 0.2777, 0.2357],\n",
       "         [0.5484, 0.5781, 0.7392, 0.6313],\n",
       "         [0.5781, 0.1654, 0.6313, 0.4918],\n",
       "         [0.7392, 0.6313, 0.9587, 0.9745],\n",
       "         [0.6313, 0.4918, 0.9745, 0.0871],\n",
       "         [0.8928, 0.4683, 0.9354, 0.9179],\n",
       "         [0.4683, 0.2547, 0.9179, 0.2860],\n",
       "         [0.9354, 0.9179, 0.4460, 0.9646],\n",
       "         [0.9179, 0.2860, 0.9646, 0.0382]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_flat = C*K*K\n",
    "# L = (size - K + 1) ** 2\n",
    "sizep = size - K + 1\n",
    "\n",
    "strided = x.as_strided((B, C, sizep, sizep, K, K), (C*size*size, size*size, size, 1, size, 1))\n",
    "\n",
    "# match shape\n",
    "strided = strided.permute(0, 1, 4, 5, 2, 3)\n",
    "strided = strided.reshape(B, C*K*K, sizep*sizep)\n",
    "print(strided.shape)\n",
    "strided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allclose = True, max diff = 0.0\n"
     ]
    }
   ],
   "source": [
    "compare(unf, strided)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to Convolution\n",
    "\n",
    "조각들을 살펴보았으니 이제 Conv 를 구현해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 1\n",
    "C_in = 4\n",
    "C_out = 8\n",
    "K = 3  # should be 3\n",
    "size = 8\n",
    "stride = 1\n",
    "padding = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(B, C_in, size, size)\n",
    "W = torch.rand(C_out, C_in, K, K)\n",
    "b = torch.rand(C_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(x):\n",
    "    return F.conv2d(x, W, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_naive(x):\n",
    "    assert stride == 1 and padding == 0 and K == 3\n",
    "    Wt = W.permute(1, 2, 3, 0)  # [C_in, K, K, C_out]\n",
    "    Wt_flat = Wt.flatten(0, 2) # [C_in*K*K, C_out]\n",
    "    out = torch.empty(B, C_out, size-(K-1), size-(K-1))\n",
    "    s = K // 2\n",
    "    for i in range(s, size-s):\n",
    "        for j in range(s, size-s):\n",
    "            si = i-s\n",
    "            sj = j-s\n",
    "            px = x[:, :, si:si+K, sj:sj+K] # [B, C_in, K, K]\n",
    "            r = (px.flatten(1) @ Wt_flat) + b\n",
    "            out[:, :, si, sj] = r\n",
    "            \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allclose = True, max diff = 3.814697265625e-06\n"
     ]
    }
   ],
   "source": [
    "compare(conv(x), conv_naive(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfold convs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4, 8, 8]), torch.Size([8, 4, 3, 3]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_unfold(x):\n",
    "    unf = F.unfold(x, K)  # [B, C_in*K*K, L]; L = H_out * W_out\n",
    "    weight = W.flatten(1)  # [C_out, C_in*K*K]\n",
    "    \n",
    "    out =  weight @ unf + b[None, ..., None]  # [B, C_out, L]\n",
    "    sizep = size - K + 1\n",
    "    return out.view(B, C_out, sizep, sizep)  # [B, C_out, H', W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allclose = True, max diff = 2.86102294921875e-06\n"
     ]
    }
   ],
   "source": [
    "compare(conv(x), conv_unfold(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unfold by as_strided\n",
    "\n",
    "- as_strided 로 reshape 안하고."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4, 8, 8]), 8, 3, 4, torch.Size([8, 4, 3, 3]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, size, K, C_in, W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_unfold_as(x):\n",
    "    sizep = size - K + 1\n",
    "    strided = x.as_strided((B, C_in, sizep, sizep, K, K), (C_in*size*size, size*size, size, 1, size, 1))\n",
    "    strided = strided.permute(0, 2, 3, 1, 4, 5)  # [B, H', W', C, K, K]\n",
    "    \n",
    "    # https://discuss.pytorch.org/t/does-as-strided-copy-data/24503/5 에 따르면,\n",
    "    # einsum 보다 gemm 을 쓰라는데. gemm 을 쓰는게 훨씬 복잡해지지 않나?\n",
    "    out = torch.einsum('bhwckl,ockl->bohw', strided, W)\n",
    "    out = out + b[None, ..., None, None]\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allclose = True, max diff = 2.86102294921875e-06\n"
     ]
    }
   ],
   "source": [
    "compare(conv(x), conv_unfold_as(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allclose = True, max diff = 0.0\n"
     ]
    }
   ],
   "source": [
    "compare(conv_unfold(x), conv_unfold_as(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expand conv\n",
    "\n",
    "Ref: https://github.com/pytorch/fairseq/blob/v0.9.0/fairseq/modules/dynamic_convolution.py#L173\n",
    "\n",
    "skip now ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
