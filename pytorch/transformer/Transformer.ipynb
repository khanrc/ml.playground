{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer\n",
    "\n",
    "http://nlp.seas.harvard.edu/2018/04/03/attention.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://nlp.seas.harvard.edu/images/the-annotated-transformer_14_0.png\" width=\"30%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "용어 정리. \n",
    "\n",
    "- N번 반복되는 각 layer\n",
    "- 그 안에 residual connection + layer norm + Sublayer(ff or attn) = sub-layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "# from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set_context(context=\"talk\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.1.post2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture. Base for this and many other models.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "        \n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        \"Take in and process masked src and target sequences.\"\n",
    "        return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask)\n",
    "\n",
    "    # Q. src_mask 가 뭘까?\n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "\n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sublayer 를 wrapping 하는 sub-layer module.\n",
    "# forward 시 Sublayer 를 인자로 받아서 그걸 내보내고, layer norm / dropout / residual connection 적용.\n",
    "# 특이한 점이 하나 있는데, 그림과는 달리 LN => Layer => res-con 형태. \n",
    "# 때문에 layer 를 스택하는 Encoder/Decoder module 을 보면 마지막에 LN 을 한번 더 붙여준다.\n",
    "# 다만 이렇게 되면 논문과는 달리 제일 앞에 LN 이 추가되게 되는데... 별로 상관 없으려나. 왜 굳이 이렇게 하는지 잘 모르겠다.\n",
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer 가 하나의 블록에 해당.\n",
    "# 각 layer 가 N(=6) 번 스택되어 인코더를 이룬다.\n",
    "# 위에서 언급했듯 sub-layer 가 norm-first 구조라서 최종 결과에는 한번 더 LayerNorm 을 씌워서 결과로 내보냄.\n",
    "class Encoder(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        \"Pass the input (and mask) through each layer in turn.\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder block.\n",
    "# self-attn layer + feed-forward layer\n",
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask)) # self-attention\n",
    "        return self.sublayer[1](x, self.feed_forward) # feed-forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder 와 마찬가지로 layer 를 받아서 N(=6) 번 스택.\n",
    "# Encoder 와의 차이는 encoder hidden state 인 memory 와,\n",
    "# 마스크가 소스/타겟으로 나뉜다.\n",
    "class Decoder(nn.Module):\n",
    "    \"Generic N layer decoder with masking.\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-attn, enc-dec attn, ff 세가지 sub-layer 를 받아서 하나의 layer 를 만든다.\n",
    "# 첫번째 sub-layer 인 self-attn 에서는 target mask 가,\n",
    "# 두번째 sub-layer 인 enc-dec attn 에서는 source mask 가 사용된다.\n",
    "class DecoderLayer(nn.Module):\n",
    "    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    " \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        \"Follow Figure 1 (right) for connections.\"\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        return self.sublayer[2](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    \"\"\"Mask out subsequent positions.\n",
    "    3가지 방법이 있음:\n",
    "    1) torch.ones(size, size, dtype=torch.uint8).tril().unsqueeze(0)\n",
    "    2) torch.from_numpy(np.tri(size, dtype=np.uint8)).unsqueeze(0)\n",
    "    3) 아래 주석처리된 오리지널 코드.\n",
    "    \"\"\"\n",
    "    return torch.ones(size, size, dtype=torch.uint8).tril().unsqueeze(0)\n",
    "    # 2)\n",
    "#     mask = np.tri(size, dtype=np.uint8)\n",
    "#     return torch.from_numpy(mask).unsqueeze(0)\n",
    "#     attn_shape = (1, size, size)\n",
    "    # 3)\n",
    "#     mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "#     return torch.from_numpy(mask) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상식적인 그 형태 그대로의 마스크.\n",
    "subsequent_mask(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention\n",
    "\n",
    "<img src = http://nlp.seas.harvard.edu/images/the-annotated-transformer_33_0.png width=\"10%\" />\n",
    "\n",
    "$$\\mathrm{Attention}(Q, K, V) = \\mathrm{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"\"\" Compute 'Scaled Dot Product Attention'\n",
    "    query: [B, Q, d_k]\n",
    "    key  : [B, K, d_k]\n",
    "    value: [B, V, d_v]\n",
    "    또는, [B, H, Q, d_k] 의 형태로 H (n_heads) 가 끼어들 수 있음. 아니 항상 그렇겠네...\n",
    "    \"\"\"\n",
    "    d_k = query.size(-1)\n",
    "    \n",
    "    # attention score 계산\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "\n",
    "    # masking. 0 인 곳은 -inf 로 채워준다.\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    \n",
    "    # attention distribution\n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    \n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    \n",
    "    # return attention outputs & attention distribution\n",
    "    return torch.matmul(p_attn, value), p_attn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-head attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://nlp.seas.harvard.edu/images/the-annotated-transformer_38_0.png\" width=\"20%\" />\n",
    "\n",
    "$$\n",
    "\\mathrm{MultiHead}(Q, K, V) = \\mathrm{Concat}(\\mathrm{head_1}, ...,\n",
    "\\mathrm{head_h})W^O    \\\\\n",
    "    \\text{where}~\\mathrm{head_i} = \\mathrm{Attention}(QW^Q_i, KW^K_i, VW^V_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    h = 8\n",
    "    d_model = 512\n",
    "    d_k = d_v = 64\n",
    "    \"\"\"\n",
    "    def __init__(self, h, d_model, dropout_rate=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None # attention distribution\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            # Source mask: padding 만 마스킹. [B, 1, N] 으로 들어옴.\n",
    "            #   모든 단어가 패딩을 제외하면 전부 서로를 볼 수 있음.\n",
    "            # Target mask: padding + 자기 오른쪽 (이후 정보) 은 안 보도록. [B, N-1, N-1] 로 들어옴.\n",
    "            #   차례대로 자기가 볼 수 있는 마스크를 의미함. target_mask[b, q, k] => q 가 이 k 를 볼 수 있는가?\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
    "        # QW, KW, VW 계산\n",
    "        # 원래는 W (W_q, W_k, W_v) 는 [d_model, d_k] 다. 근데 어차피 multi-head 니까 한방에 만드는 것.\n",
    "        # 그래서 linear projection 후 view/transpose 를 통해 차원을 맞춰준다.\n",
    "        # query 만 차원 설명하면: [B, h, Q, d_k]. 앞에 두개는 배치와 헤드이므로 무시하면 우리가 원하던 형태인 [Q, d_k] 가 된다!\n",
    "#         query, key, value = \\\n",
    "#             [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "#              for l, x in zip(self.linears, (query, key, value))]\n",
    "        # 동일함:\n",
    "        query = self.linears[0](query).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "        key   = self.linears[1]( key ).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "        value = self.linears[2](value).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "        \n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        # 계산한 projected Q, K, V 에다가 attention 적용\n",
    "        # x 는 attention output, self.attn 은 attention distribution.\n",
    "        # x: [B, h, Q, d_k]\n",
    "        x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout)\n",
    "        \n",
    "        # 3) \"Concat\" using a view and apply a final linear. \n",
    "        # x => [B, Q, h, d_k] => [B, Q, d_model]. 즉, concat(heads)\n",
    "        x = x.transpose(1, 2).contiguous().view(nbatches, -1, self.h * self.d_k)\n",
    "        \n",
    "        # 4) last linear projection\n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Position-wise Feed-Forward Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사실 특별할 것 없는 2-layer FC.\n",
    "# 단, 입력이 [B, Q, d_model] 로 들어오면 이 3번째 차원에 대한 FC 다.\n",
    "# Linear module 은 원래 마지막 차원에 대해서 FC 를 수행함.\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # output: logits.\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding and Softmax\n",
    "\n",
    "- 디코더의 마지막에 들어가는 linear softmax 의 linear (Generator) 는 word vector => vocab 으로, `[d_model, vocab]` FC.\n",
    "- Embedding 은 vocab => word vector 로, `[vocab, d_model]` FC.\n",
    "\n",
    "따라서 두 weight 는 공유할 수 있다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word vector size = d_model\n",
    "# vocabulary size = vocab\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        # look up table\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 재미있는 점은 embedding 할때는 softmax 와 반대로 sqrt(d_model) 을 곱해줌!\n",
    "        return self.lut(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder 의 마지막 Linear softmax 함수\n",
    "class Generator(nn.Module):\n",
    "    \"Define standard linear + softmax generation step.\"\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Encoding\n",
    "\n",
    "- Watermark for positional information injection\n",
    "- 포지션 정보를 넣기 위해 사용함. 각 포지션에 맞는 워드 벡터 크기의 포지션 벡터가 생성되고, 이를 그냥 더함으로써 포지션 정보를 입힌다.\n",
    "\n",
    "$$PE_{(pos,2i)} = sin(pos / 10000^{2i/d_{\\text{model}}}) \\\\\n",
    "PE_{(pos,2i+1)} = cos(pos / 10000^{2i/d_{\\text{model}}})\n",
    "$$\n",
    "\n",
    "- pos 는 단어 위치, 2i / 2i+1 은 단어의 워드 임베딩 차원.\n",
    "- 즉 query \\[Q, d_model\\] 이 들어오면 `query[pos, 2i(+1)]` 에 이걸 그대로 박아넣으면 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout_rate=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        # 원래 수식과 다르게 log space 에서 계산한 후 exp 를 씌워줘서 복구.\n",
    "        # 아마 10000 의 2i/d_model 제곱을 하면 값이 너무 커지는 걸 우려한 것 같음.\n",
    "        # 근데 어차피 2i/d_model 의 최대값이 1인데 이걸 걱정할 필요가 있나...?\n",
    "#         pe = torch.zeros(max_len, d_model) # [L, D]\n",
    "#         position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1) # [L, 1]\n",
    "#         div_term = torch.exp(torch.arange(0, d_model, 2, dtype=torch.float32) * -(np.log(10000.0) / d_model)) # [D]\n",
    "#         # position * div_term = [L, D] (boradcasting)\n",
    "#         pe[:, 0::2] = torch.sin(position * div_term)\n",
    "#         pe[:, 1::2] = torch.cos(position * div_term)\n",
    "#         pe = pe.unsqueeze(0) # [1, L, D]; expand dim for batch dim\n",
    "        \n",
    "        \n",
    "        pe = torch.empty(max_len, d_model) # [L, D]\n",
    "        pos = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1) # [L, 1]\n",
    "        indices = torch.arange(0, d_model, 2, dtype=torch.float32) # [D / 2]\n",
    "        div = 10000. ** (indices / d_model)\n",
    "        pe[:, 0::2] = torch.sin(pos / div)\n",
    "        pe[:, 1::2] = torch.cos(pos / div)\n",
    "        pe.unsqueeze_(0).requires_grad_(False) #.to(device) # expand batch dim\n",
    "        \n",
    "        # register_buffer 를 통해 이 module 의 persistent state (no parameter) 로 등록할 수 있다.\n",
    "        # BN 의 running mean / var 같은 값을 이걸로 등록. 파라메터는 아니라서 학습이 되는 건 아니지만\n",
    "        # 값을 계속 유지하고, 저장할때도 저장해줘야 하는 등 그라디언트를 계산하지 않는 것만 빼면 파라메터와 동일하게 취급된다.\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # No-gradient flow. 어차피 variable 이 없어서 상관 없을 것 같기는 한데.\n",
    "#         x = x + Variable(self.pe[:, :x.size(1)], requires_grad=False)\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-aaefa5d21aa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPositionalEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6bc25f88d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "pe = PositionalEncoding(20, 0)\n",
    "pe.to(device)\n",
    "y = pe.forward(torch.zeros(1, 100, 20).to(device))\n",
    "plt.plot(np.arange(100), y[0, :, 4:8].cpu().numpy())\n",
    "plt.legend([\"dim %d\"%p for p in [4,5,6,7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "    c = copy.deepcopy\n",
    "    \n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    \n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N), # [self-attn, ff] * 6 스택.\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N), # [self-attn, encdec-attn, ff] * 6 스택.\n",
    "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)), # src_vocab => wv embedding + pos\n",
    "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)), # tgt_vocab => wv embedding + pos\n",
    "        Generator(d_model, tgt_vocab) # Last linear softmax\n",
    "    )\n",
    "    \n",
    "    # This was important from their code. \n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1: # weight 인지 체크\n",
    "            nn.init.xavier_uniform_(p)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic data\n",
    "\n",
    "- Data copy task\n",
    "- 그냥 입력으로 들어온 데이터를 카피해서 출력하는 것을 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(V, batch, nbatches):\n",
    "    \"Generate random data for a src-tgt copy task.\"\n",
    "    for i in range(nbatches):\n",
    "        data = torch.from_numpy(np.random.randint(1, V, size=(batch, 10)))\n",
    "        data[:, 0] = 1\n",
    "#         src = Variable(data, requires_grad=False)\n",
    "#         tgt = Variable(data, requires_grad=False)\n",
    "        src = data.to(device)\n",
    "        tgt = data.to(device)\n",
    "        yield Batch(src, tgt, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    \"Object for holding a batch of data with mask during training.\"\n",
    "    def __init__(self, src, trg=None, pad=0):\n",
    "        \"\"\"\n",
    "        src: source sentence. word index 형태로 들어오는 듯.\n",
    "        trg: target sentence. 마찬가지로 word index 형태.\n",
    "             트레이닝 시에는 이전 아웃풋이 아니라 \"true target\" word 를 입력으로 넣어줌.\n",
    "             이를 위해 decoder input trg / decoder target output trg_y 로 나눈 것.\n",
    "        pad: padding index. masking 을 할 때 padding 은 무조건 못 보게 0으로 마스킹.\n",
    "             생각해보면 당연한데, padding 이라는 건 문장이 끝났다는 것임. 이건 안 보는게 맞음.\n",
    "        \"\"\"\n",
    "        self.src = src\n",
    "        # src: [B, N] (N: 단어 개수)\n",
    "        # src_mask: [B, 1, N]\n",
    "        self.src_mask = (src != pad).unsqueeze(-2) # 뒤에서 두번째에 차원을 하나 추가\n",
    "        if trg is not None:\n",
    "            self.trg = trg[:, :-1]\n",
    "            self.trg_y = trg[:, 1:]\n",
    "            self.trg_mask = self.make_std_mask(self.trg, pad)\n",
    "            self.ntokens = (self.trg_y != pad).sum(dtype=torch.float32) # trg_y 의 총 단어 개수\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_std_mask(tgt, pad):\n",
    "        \"\"\"Create a mask to hide padding and future words.\n",
    "        subsequent_mask() 로 마스킹을 하는데 단: padding 도 못 보게 마스킹.\n",
    "        \"\"\"\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2) # [B, 1, N]\n",
    "#         tgt_mask = tgt_mask & Variable(subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data))\n",
    "        # subsequent_mask: [1, N, N]\n",
    "        ss_mask = subsequent_mask(tgt.size(-1)).type_as(tgt_mask)\n",
    "        tgt_mask = tgt_mask & ss_mask\n",
    "        return tgt_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data and Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip\n",
    "# Synthetic data 에는 필요없는 듯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "\n",
    "- Adam with \n",
    "    - beta1 = 0.9\n",
    "    - beta2 = 0.98\n",
    "    - eps = 1e-9\n",
    "- LR decay\n",
    "    - $ lrate = d_{\\text{model}}^{-0.5} \\cdot \\min({step\\_num}^{-0.5},~{step\\_num} \\cdot {warmup\\_steps}^{-1.5}) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 왜 이 옵티마이저 이름이 Noam인가? 모르겠음. 논문에 딱히 그런 얘기 없는 것 같은데.\n",
    "# 그냥 optimizer + lr control => adam + warmup + lr decay\n",
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "        \n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def rate(self, step = None):\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        lrate = self.model_size ** (-0.5) * min(step ** (-0.5), step * self.warmup ** (-1.5))\n",
    "        return self.factor * lrate\n",
    "        \n",
    "def get_std_opt(model):\n",
    "    adam_opt = torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9)\n",
    "    return NoamOpt(model.src_embed[0].d_model, 2, 4000, adam_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate schedule plot\n",
    "# Three settings of the lrate hyperparameters.\n",
    "opts = [NoamOpt(512, 1, 4000, None), \n",
    "        NoamOpt(512, 1, 8000, None),\n",
    "        NoamOpt(256, 1, 4000, None)]\n",
    "plt.plot(np.arange(1, 20000), [[opt.rate(i) for opt in opts] for i in range(1, 20000)])\n",
    "plt.legend([\"512:4000\", \"512:8000\", \"256:4000\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization: Label Smoothing\n",
    "\n",
    "- 논문하곤 좀 다르게 구현되어 있는 듯.\n",
    "- 논문에선 그냥 e = 0.1 이라는데.\n",
    "\n",
    "원문 텍스트:\n",
    "\n",
    "We implement label smoothing using the KL div loss. Instead of using a one-hot target distribution, we create a distribution that has confidence of the correct word and the rest of the smoothing mass distributed throughout the vocabulary.\n",
    "\n",
    "One-hot target distribution 대신에, smoothing 을 적용한 distribution 을 만들어서 적용. 똑같은 건가?\n",
    "아래 실험 결과를 보면, `true target = 1 - smoothing` 이 되고 나머지는 `smoothing / N_others` 로 채움."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothing(nn.Module):\n",
    "    \"\"\"Implement label smoothing.\n",
    "    이유는 잘 모르겠으나, 여기서 size_average=False 로 주고, 나중에 계산할때 토큰수로 나눠줌.\n",
    "    패딩 때문에 그런가?\n",
    "    \n",
    "    smoothing 자체는 자연스럽게 주는데,\n",
    "    이걸 KLD 로 계산하면... CE 처럼 계산이 되나?\n",
    "    참고: https://icim.nims.re.kr/post/easyMath/550\n",
    "    KLD(y,p) = CE + ylogy. 문제는 ylogy 가 p, 즉 네트워크와 관련 없는 값이므로 최적화할때는 무시할 수 있음.\n",
    "    따라서 optimize KLD(y,p) = optimize CE(y,p). 단, pytorch 의 CE 는 분포를 입력으로 할 수 없고 \n",
    "    target class label 만 넣을 수 있어서 스무딩을 적용할 수가 없어서 KLD 를 쓴 것. \n",
    "    그냥 직접 곱해서 계산해도 될 것 같은데...;\n",
    "    \"\"\"\n",
    "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(reduction='sum')\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "        self.true_dist = None\n",
    "        \n",
    "    def forward(self, x, target):\n",
    "        assert x.size(1) == self.size\n",
    "        #true_dist = x.clone()\n",
    "        true_dist = x.new_empty(x.size())\n",
    "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
    "        # dim=1 에 대해서, confidence 값을 target index 에 뿌리는 것임.\n",
    "        true_dist.scatter_(1, target.unsqueeze(1), self.confidence)\n",
    "        true_dist[:, self.padding_idx] = 0\n",
    "        # padding_idx 와 같은 target 의 인덱스들을 mask 에 담음\n",
    "        # 즉, 타겟 자체가 패딩이면 싹다 0으로 채움\n",
    "        mask = torch.nonzero(target == self.padding_idx)\n",
    "        if mask.dim() > 1:\n",
    "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        self.true_dist = true_dist\n",
    "        \n",
    "#         return self.criterion(x, Variable(true_dist, requires_grad=False))\n",
    "        return self.criterion(x, true_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of label smoothing.\n",
    "# 제일 앞이 다 0인건 0번이 패딩이라서 그러함. 패딩에는 smoothing 값을 주지 않는다.\n",
    "# vocab 에서 패딩 인덱스는 0으로 주고, 아니면 타겟 자체가 패딩이면 싹다 0으로 채움.\n",
    "crit = LabelSmoothing(5, 0, 0.4)\n",
    "predict = torch.FloatTensor([[0, 0.2, 0.7, 0.1, 0],\n",
    "                             [0, 0.2, 0.7, 0.1, 0], \n",
    "                             [0, 0.2, 0.7, 0.1, 0]])\n",
    "\n",
    "v = crit(predict.log(), torch.LongTensor([2, 1, 0]))\n",
    "\n",
    "crit.true_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "- 위에서 언급했듯, training 시에는 이전 timestep 에서 생성한 output 을 auto-regressive 하게 입력으로 넣어주는 것이 아니라, 실제로 나와야하는 true target 값을 입력으로 넣어줌\n",
    "    - 생각해보면 결국 이전 디코더가 제대로 만들었을 경우에 대해 학습을 해야 하므로 맞는 듯\n",
    "- 재미있는 것은, **이렇게 되면 decoding phase 가 encoding phase 와 같아진다!** (트레이닝 시)\n",
    "- 무슨 말이냐면, 디코더에 들어가야 할 인풋을 우리가 처음부터 다 알고있다. 따라서 굳이 앞 timestep 의 결과를 기다릴 필요 없이, 인코더처럼 전체 문장을 한방에 집어넣어서 결과를 뽑아내면 된다.\n",
    "    - 정확히 말하면 전체 문장에서 제일 앞에는 <BOS> (Beginning of Sentence) 를 넣어주고 제일 마지막 단어는 빼야 함\n",
    "- 마지막 리니어 소프트맥스는 배치처럼 각 단어에 대해서 다 적용하면 되고.\n",
    "\n",
    "단, 이건 트레이닝 시 얘기고, 실제 테스트 페이즈에서는 auto-regressive 하게 하나씩 생성해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLossCompute:\n",
    "    \"\"\"A simple loss compute and train function.\n",
    "    그냥 decoder output x 와 true label y 를 받아서 criterion 에 따라 로스 계산.\n",
    "    거기다 backward() 및 opt.step() 도 해줌.\n",
    "    재미있는 점은 norm - size_average 효과.\n",
    "    \"\"\"\n",
    "    def __init__(self, generator, criterion, opt=None):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        self.opt = opt\n",
    "        \n",
    "    def __call__(self, x, y, norm):\n",
    "        x = self.generator(x)\n",
    "        loss = self.criterion(x.contiguous().view(-1, x.size(-1)), y.contiguous().view(-1)) / norm\n",
    "        loss.backward()\n",
    "        if self.opt is not None:\n",
    "            self.opt.step()\n",
    "            self.opt.optimizer.zero_grad()\n",
    "        return loss.item() * norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(data_iter, model, loss_compute):\n",
    "    \"\"\"Standard Training and Logging Function\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    tokens = 0\n",
    "    \n",
    "    for i, batch in enumerate(data_iter):\n",
    "        out = model.forward(batch.src, batch.trg, batch.src_mask, batch.trg_mask)\n",
    "        loss = loss_compute(out, batch.trg_y, batch.ntokens)\n",
    "        total_loss += loss\n",
    "        total_tokens += batch.ntokens\n",
    "        tokens += batch.ntokens\n",
    "        \n",
    "        if i % 50 == 1:\n",
    "            elapsed = time.time() - start\n",
    "            print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" % (i, loss / batch.ntokens, tokens / elapsed))\n",
    "            start = time.time()\n",
    "            tokens = 0\n",
    "            \n",
    "    return total_loss / total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train the simple copy task.\n",
    "V = 11\n",
    "\n",
    "criterion = LabelSmoothing(size=V, padding_idx=0, smoothing=0.0)\n",
    "# criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "model = make_model(V, V, N=2)\n",
    "model_opt = NoamOpt(model.src_embed[0].d_model, 1, 400,\n",
    "        torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "\n",
    "model.to(device)\n",
    "criterion.to(device)\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    train_loss = run_epoch(data_gen(V, 30, 20), model, SimpleLossCompute(model.generator, criterion, model_opt))\n",
    "    \n",
    "    model.eval()\n",
    "    eval_loss = run_epoch(data_gen(V, 30, 5), model, SimpleLossCompute(model.generator, criterion, None))\n",
    "    print(eval_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src).to(device)\n",
    "    for i in range(max_len-1):\n",
    "        out = model.decode(memory, src_mask, ys, subsequent_mask(ys.size(1)).type_as(src))\n",
    "        prob = model.generator(out[:, -1]) # all batch, last query (마지막 단어)\n",
    "        _, next_word = torch.max(prob, dim = 1)\n",
    "        next_word = next_word.item()\n",
    "        ys = torch.cat([ys, torch.ones(1, 1).type_as(src).fill_(next_word)], dim=1)\n",
    "    return ys\n",
    "\n",
    "model.eval()\n",
    "src = torch.LongTensor([[1,2,3,4,5,6,7,8,9,10]]).to(device)\n",
    "src_mask = torch.ones(1, 1, 10).to(device)\n",
    "print(greedy_decode(model, src, src_mask, max_len=10, start_symbol=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
